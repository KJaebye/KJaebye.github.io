<!doctype html>
<html>
<head>

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Kangyao Huang</title>
<link href="styles/aboutPageStyle.css" rel="stylesheet" type="text/css">
<link rel="icon" href="./profile/ride.jpg"><style type="text/css">
</style>

</head>

<body alink = "#282727" vlink = "#9b9b9b" link = "#9b9b9b">
<!-- Header content -->
<header>
    <div class="profilePhoto"> 
        <img src="profile/hky_avatar.jpg" alt="sample" width="200">
        <!-- <img src="profile/hky.jpg" alt="sample" width="200"> -->
        <!-- <img src="profile/hky_life.jpg" alt="sample" width="200"> -->
    </div>
    <!-- Identity details -->
    <section class="profileHeader">
        <h1 style="line-height: 30px;font-size: 28px;margin-bottom: auto;">Kangyao Huang&emsp;&emsp;<img src="profile/name.png" width="80" style="margin-bottom: -5px;"></h1>
        <h3>PhD Candidate | AI Researcher | Aerospace & Robotics Engineer</h3>
        <hr>
        <p style="line-height: 15px;font-size: 12px;margin-bottom: auto;">I am Kangyao Huang (黄康尧 in Chinese) from China, working towards AI and robotics research and application. Currently, I am pursuing a PhD degree in Computer Science at <a style="color:#6e02ba" href="https://www.tsinghua.edu.cn/">Tsinghua University(THU)</a> under the supervision of Prof. <a href="https://sites.google.com/site/thuliuhuaping">Huaping Liu</a>.
            Besides, I also hold an MRes degree in Control & Systems Engineering from <a style="color: rgb(5, 103, 196);" href="https://www.sheffield.ac.uk/acse">ACSE</a>, <a style="color: rgb(5, 103, 196);" href="https://www.sheffield.ac.uk/">the University of Sheffield(UoS)</a>, UK., supervised by Prof. <a href="https://scholar.google.co.uk/citations?user=W7ePGWYAAAAJ&hl=en">John Oyekan</a>, and a BEng degree in Aircraft Design & Engineering from <a style="color: rgb(25, 74, 179);" href="https://www.nwpu.edu.cn/">Northwestern Polytechnical
            University (NWPU)</a>, China. I had several years start-up experience in aerospace and robotics sectors, serving as CEO, technical director, and UAV engineer.
            <br>
            <br> I have experience in EAI, UAV, and autonomous driving. I lead the development of the first generation of Tsinghua Mengshi intelligent flying car which is <b>the world's first pure electric rotorcraft unmanned flying vehicle</b> with integrated intelligent driving function. My current research interest is in Embodied AI for virtual and real world practice. I also follow ideas on aerial robotics and reconstruction. I am doing a startup @emNavi Tech, focusing on the EAI enhanced navigation and related sensors. If you have any ideas, please do not hesitate to email me directly.<br></p>
    </section>
    <aside class="socialNetworkNavBar">
        <div class="socialNetworkNav"> 
            <a href="mailto:kangyao.huang@outlook.com">
                <img src="profile/mail.png"  alt="sample" width="30" ></a>
        </div>
        <div class="socialNetworkNav">
            <a href="https://github.com/kjaebye" target="_blank">
                <img src="profile/github.png" alt="sample" width="30"></a>
        </div>
        <div class="socialNetworkNav"> 
            <a href="https://scholar.google.com/citations?user=df7fnwQAAAAJ" target="_blank">
                <img src="profile/scholar.png"  alt="sample" width="30"></a>
        </div>
        <div class="socialNetworkNav">
            <a href="" target="_blank">
                <img src="profile/linkedin.png"  alt="sample" width="30"></a>
        </div>
        <div class="socialNetworkNav">
            <a href="https://orcid.org/0000-0002-5708-2620" target="_blank">
                <img src="profile/orcid.png"  alt="sample" width="30"></a>
        </div>
        <div class="socialNetworkNav">
            <a href="https://www.xiaohongshu.com/user/profile/638ceaa1000000001f01ce42" target="_blank">
                <img src="profile/xhs.png"  alt="sample" width="30"></a>
        </div>
    </aside>
</header>

<section class="mainContent"> 
    <section class="section2">
        <h2 class="sectionTitle">Top Open-source Projects</h2>
        <!-- <hr class="sectionTitleRule"> -->
        <hr class="sectionTitleRule2">

    <!-- emNavi  -->
    <div onmouseout="emNavi_stop()" onmouseover="emNavi_start()">	  
        <div class="sectionContent" style="padding:0px;vertical-align:middle">
            <div class="one">
                <div class="two" id="emNavi_image">
                    <video  width="100%" height="100%" muted="" autoplay="" loop="">
                        <source src="material/X152b-ego.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <img src="material/X152b-ego.jpg" width="100%">
            </div>
            <script type="text/javascript">
                function emNavi_start() {
                document.getElementById('emNavi_image').style.opacity = "1";
                }

                function emNavi_stop() {
                document.getElementById('emNavi_image').style.opacity = "0";
                }
                emNavi_stop()
            </script>
        </div>
        <section class="section2Content">
            <h2 class="sectionContentTitle"><img src="material/logo1.png" alt="emNavi" style="height: 50px; vertical-align: middle;"></h2>
                <p style="font-size: 12px;"><b>emNavi</b> derives from "Embodied Navigation". 
                    The vision of emNavi is to make navigation more intelligent. Besides, emNavi is an open-sourced project that re-construct and optimize the navigation-related SoTA (state of the art) 
                    algorithms and apply them on robots, especially aerial robots, to promote the implementation of Embodied AI 
                    on mobile robots. </p>
            </h2>

        </section>
        <aside class="externalResourcesNav" style="margin-top:0%"> 
            <div class="dropdown">
                <span></span><a href="https://emnavi.tech/" target="_blank"><b>emNavi</b></a>
            </div>
            <div class="dropdown">
                <span></span><a href="https://emnavi.tech/droneKit/" target="_blank">X152b</a>
            </div>
            <div class="dropdown">
                <span></span><a href="https://emnavi.tech/AirGym/" target="_blank">Sim2Real</a>
            </div>
        </aside>
    </div>
    <br>

    <!-- AirGym-Sim  -->
    <div onmouseout="airgym_sim_stop()" onmouseover="airgym_sim_start()">	  
        <div class="sectionContent" style="padding:0px;vertical-align:middle">
            <div class="one">
                <div class="two" id="airgym-sim_image">
                    <video  width="100%" height="100%" muted="" autoplay="" loop="">
                        <source src="material/airgym-sim.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <img src="material/airgym-sim.png" width="100%">
            </div>
            <script type="text/javascript">
                function airgym_sim_start() {
                document.getElementById('airgym-sim_image').style.opacity = "1";
                }

                function airgym_sim_stop() {
                document.getElementById('airgym-sim_image').style.opacity = "0";
                }
                airgym_sim_stop()
            </script>
        </div>
        <section class="section2Content">
            <h2 class="sectionContentTitle"> <img src="material/airgym-logo.png" alt="emNavi" style="height: 30px; vertical-align: middle;"> Quadrotor DRL Simulation Platform  </h2>
                <p style="font-size: 12px;"><b>AirGym</b> is an open souce Python quadrotor simulator based on IsaacGym, a part of AirGym series Sim-to-Real working flow. It provides a high-fidelity dynamics and Deep Reinforcement Learning (DRL) framework for quadrotor robot learning research. Furthermore, we also provide toolkits for transferring policy from AirGym simulator to the real quadrotor emNavi-X152b, making Sim-to-Real possible.  </p>
            </h2>

        </section>
        <aside class="externalResourcesNav" style="margin-top:0%"> 
            <div class="dropdown">
                <span></span><a href="https://github.com/emNavi/AirGym" target="_blank">Github</a>
            </div>
            <div class="dropdown">
                <span></span><a href="https://emnavi.tech/AirGym/" target="_blank">Project Page</a>
            </div>
        </aside>
    </div>
    <br>

</section>

<section class="mainContent"> 
    <section class="section2">
        <h2 class="sectionTitle">Book</h2>
        <!-- <hr class="sectionTitleRule"> -->
        <hr class="sectionTitleRule2">

        <!-- Book Content -->
        <div class="book-container">
            <div class="book-cover">
                <img src="material/book_springer.png" alt="cover" class="book-image">
            </div>
            <div class="book-info"> 
                <h3 class="sectionContentTitle">
                    <a href="https://link.springer.com/book/10.1007/978-981-96-5871-8">Embodied Multi-Agent Systems</a>
                </h3>
                <h3 class="sectionContentSubTitle" style="font-size: 11px;"> 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>,
                    <a href="" target="_blank">Xinzhu Liu</a>,
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=OCauNHUAAAAJ" target="_blank">Di Guo</a>
                </h3>
                <p class="book-summary;" style="font-size: 11px;">
                    This book focuses on active perception and interactive learning for embodied multi-agent systems. The remarkable reasoning, perception, and decision-making capabilities demonstrated by LLM in recent years have brought significant opportunities for the exploration of artificial general intelligence (AGI). This results in the development of increasingly larger models and a higher consumption of data. The ultimate goal is to achieve AGI through a unified brain model. However, when it comes to embodied agents, this strategy encounters considerable challenges due to the variety in morphology and function among these agents. It is neither feasible nor desirable to expect all embodied agents to conform to a single morphology. Instead, we should embrace the principles of biodiversity, promoting the existence, collaboration, and interaction of various forms. This recognition has motivated our research into embodied multi-agent systems. During this process, we have realized that active perception, along with the interactive learning capabilities that stem from it, plays a crucial role in fostering collaboration and synergy among multiple embodied agents.
                </p>
                <p style="font-size: 10px;color: rgba(141, 20, 139, 0.579);">
                    We would like to thank Prof. Angelo Cangelosi, Prof. David Hsu, Prof. John Aloimonos who provide lots of support. We would like to express our gratitude to Dr. Hongbo Li from <b>Geek+</b> and Dr. Tianlei Zhang from <b>TrunkTech</b> for their invaluable support in our study of embodied multi-agent collaboration. Additionally, we would like to express our sincere gratitude to Chenxu Wang, Xinghang Li, Juan Wang, Peiyan Li, Pingcheng Jian, and Chuye Hong for their significant assistance in preparing the figures and proofreading the book.
                </p>
            </div>
        </div>

    </section>
</section>
<style>
    .book-container {
        display: flex;
        margin-top: 20px;
        gap: 30px;
    }
    
    .book-cover {
        flex: 0 0 160px;
    }
    
    .book-image {
        width: 100%;
        height: auto;
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    
    .book-info {
        flex: 1;
    }
    
    .book-title {
        color: #333;
        margin-bottom: 15px;
        font-size: 1.5em;
    }
    
    .book-summary {
        line-height: 1.6;
        color: #555;
    }
</style>

<!-- content -->
<section class="mainContent"> 
    <section class="section2">
        <h2 class="sectionTitle">Publications</h2>
        <!-- <hr class="sectionTitleRule"> -->
        <hr class="sectionTitleRule2">

        <!-- airgym-->
        <div onmouseout="airgym_stop()" onmouseover="airgym_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="airgym_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/airgym.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/airgym.jpg" width="100%" height="100%">
                </div>
                <script type="text/javascript">
                    function airgym_start() {
                    document.getElementById('airgym_image').style.opacity = "1";
                    }

                    function airgym_stop() {
                    document.getElementById('airgym_image').style.opacity = "0";
                    }
                    airgym_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang*</b>, 
                    <a>Hao Wang*</a>,
                    <a>Yu Luo</a>,
                    <a>Jingyu Chen</a>,
                    <a>Jintao Chen</a>,
                    <a>Xiangkui Zhang</a>,
                    <a>Xiangyang Ji</a>,
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon> 
                    <a style="font-size: 12px;color: rgb(247, 121, 175);">
                        <b>*</b> contribute equally to this work
                    </a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> arXiv</em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%">
                <div class="dropdown">
                    <span></span><a href="https://emnavi.tech/AirGym/" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px;">
                            Deploying robot learning methods to a quadrotor in unstructured outdoor environments is an exciting task. Quadrotors operating in real-world environments by learning-based methods encounter several challenges: a large amount of simulator generated data required for training, strict demands for real-time processing onboard, and the sim-to-real gap caused by dynamic and noisy conditions. Current works have made a great breakthrough in applying learning-based methods to end-to-end control of quadrotors, but rarely mention the infrastructure system training from scratch and deploying to reality, which makes it difficult to reproduce methods and applications. To bridge this gap, we propose a platform that enables the seamless transfer of end-to-end deep reinforcement learning (DRL) policies. We integrate the training environment, flight dynamics control, DRL algorithms, the MAVROS middleware stack, and hardware into a comprehensive workflow and architecture that enables quadrotors' policies to be trained from scratch to real-world deployment in several minutes. Our platform provides rich types of environments including hovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and planning in unknown environments, as a physical experiment benchmark. Through extensive empirical validation, we demonstrate the efficiency of proposed sim-to-real platform, and robust outdoor flight performance under real-world perturbations. Details can be found from our website https://emnavi.tech/AirGym/.

                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="" target="_blank">Code</a></div>
                <div class="dropdown"><span></span><a href="https://emnavi.tech/AirGym/" target="_blank">Video</a></div>
            </aside>
        </div>
        <br>

        <!-- d_hrl-->
        <div onmouseout="d_hrl_stop()" onmouseover="d_hrl_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="d_hrl_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2024dhrl.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2024dhrl.png" width="100%" height="100%">
                </div>
                <script type="text/javascript">
                    function d_hrl_start() {
                    document.getElementById('d_hrl_image').style.opacity = "1";
                    }

                    function d_hrl_stop() {
                    document.getElementById('d_hrl_image').style.opacity = "0";
                    }
                    d_hrl_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Learning a Distributed Hierarchical Locomotion Controller for Embodied Cooperation </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a>Chuye Hong*</a>,
                    <b>Kangyao Huang*</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon> 
                    <a style="font-size: 12px;color: rgb(247, 121, 175);">
                        <b>*</b> contribute equally to this work
                    </a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em>Conference on Robot Learning (<b>CoRL</b>) 2024</em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%">
                <div class="dropdown">
                    <span></span><a href="https://d-hrl.github.io/" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            In this work, we propose a distributed hierarchical locomotion control strategy for whole-body 
                            cooperation and demonstrate the potential for migration into large numbers of agents. 
                            Our method utilizes a hierarchical structure to break down complex tasks into smaller, 
                            manageable sub-tasks. By incorporating spatiotemporal continuity features, we establish the 
                            sequential logic necessary for causal inference and cooperative behaviour in sequential tasks, 
                            thereby facilitating efficient and coordinated control strategies. Through training within this 
                            framework, we demonstrate enhanced adaptability and cooperation, leading to superior performance in
                             task completion compared to the original methods. Moreover, we construct a set of environments as 
                             the benchmark for embodied cooperation.

                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="publications/2024_CoRL_Learning a Distributed Hierarchical Locomotion Controller for Embodied Cooperation.pdf" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="" target="_blank">Code</a></div>
                <div class="dropdown"><span></span><a href="https://d-hrl.github.io/" target="_blank">Video</a></div>
            </aside>
        </div>
        <br>

        <!-- 2024ijcai-->
        <div onmouseout="ijcai24_stop()" onmouseover="ijcai24_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="ijcai24_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2024ijcai.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2024ijcai.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function ijcai24_start() {
                    document.getElementById('ijcai24_image').style.opacity = "1";
                    }

                    function ijcai24_stop() {
                    document.getElementById('ijcai24_image').style.opacity = "0";
                    }
                    ijcai24_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> CompetEvo: Towards Morphological Evolution from Competition </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=OCauNHUAAAAJ" target="_blank">Di Guo</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a style="color: #999;">Xiangyang Ji</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon> 
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em>International Joint Conference
                        on Artificial  Intelligence (<b>IJCAI</b>) 2024 </em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://competevo.github.io/" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            Training an agent to adapt to specific tasks through co-optimization of morphology and control has 
                            gradually attracted attention. However, whether there exists an optimal configuration and tactics for 
                            agents in a multiagent competition scenario is still an issue that is challenging to definitively conclude. 
                            In this context, we propose competitive evolution (CompetEvo), which co-evolves agents' designs and tactics in 
                            confrontation. We build arenas consisting of three animals and their evolved derivatives, placing agents with 
                            different morphologies in direct competition with each other. The results reveal that our method enables agents 
                            to evolve a more suitable design and strategy for fighting compared to fixed-morph agents, allowing them to 
                            obtain advantages in combat scenarios. Moreover, we demonstrate the amazing and impressive behaviors that emerge 
                            when confrontations are conducted under asymmetrical morphs.

                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="publications/2024_IJCAI_CompetEvo.pdf" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/KJaebye/competevo" target="_blank">Code</a></div>
                <div class="dropdown"><span></span><a href="https://competevo.github.io/" target="_blank">Video</a></div>
            </aside>
        </div>
        <br>

        <!-- 2024icra-->
        <div onmouseout="icra24_stop()" onmouseover="icra24_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="icra24_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2024icra.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2024icra.png" width="100%">
                </div>
                <script type="text/javascript">
                    function icra24_start() {
                    document.getElementById('icra24_image').style.opacity = "1";
                    }

                    function icra24_stop() {
                    document.getElementById('icra24_image').style.opacity = "0";
                    }
                    icra24_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Stimulate the Potential of Robots via Competition </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=OCauNHUAAAAJ" target="_blank">Di Guo</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a style="color: #999;">Xiangyang Ji</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon> 
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em>IEEE International Conference on
                        Robotics and Automation (<b>ICRA</b>) 2024 </em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://github.com/KJaebye/Multiagent-Race" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            It is common for us to feel pressure in a competition environment, 
                            which arises from the desire to obtain success comparing with other individuals or opponents. 
                            Although we might get anxious under the pressure, it could also be a drive for us to stimulate our 
                            potentials to the best in order to keep up with others. Inspired by this, we propose a competitive 
                            learning framework which is able to help individual robot to acquire knowledge from the competition, 
                            fully stimulating its dynamics potential in the race. Specifically, the competition information among 
                            competitors is introduced as the additional auxiliary signal to learn advantaged actions. We further 
                            build a Multiagent-Race environment, and extensive experiments are conducted, demonstrating that robots 
                            trained in competitive environments outperform ones that are trained with SoTA algorithms in single 
                            robot environment.

                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="publications/2024_ICRA_Stimulate the potential of robots via competition.pdf" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/KJaebye/Multiagent-Race" target="_blank">Code</a></div>
                <div class="dropdown"><span></span><a href="https://youtu.be/If7brGEzYNs" target="_blank">Video</a></div>
            </aside>
        </div>
        <br>

        <!-- 2023aim  -->
        <div onmouseout="aim_stop()" onmouseover="aim_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="aim_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2023aim.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2023aim.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function aim_start() {
                    document.getElementById('aim_image').style.opacity = "1";
                    }

                    function aim_stop() {
                    document.getElementById('aim_image').style.opacity = "0";
                    }
                    aim_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> A Multi-modal Deformable Land-air Robot for Complex Environments </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=gVuaz7QAAAAJ" target="_blank">Yuanhao Huang</a>, 
                    <b>Kangyao Huang</b><ion-icon name="mail-outline"></ion-icon>, 
                    <a style="color: #999;">Xiaoyu Wang</a>, 
                    <a style="color: #999;">Dafeng Jin</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>, 
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em>IEEE/ASME International Conference on Advanced Intelligent Mechatronics (<b>AIM</b>) 2023 </em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://github.com/THU-MIR/Deformable-Aerial-Ground-Platform" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            Single locomotion robots often struggle to adapt in highly variable or uncertain environments, 
                            especially in emergencies. In this paper, a multi-modal deformable robot is introduced that can both fly and 
                            drive. Compatibility issues with multi-modal locomotive fusion for this hybrid land-air robot are solved using
                             proposed design conceptions, including power settings, energy selection, and designs of deformable structure.
                              The robot can also automatically transform between land and air modes during 3D planning and tracking. 
                              Meanwhile, we proposed a algorithms for evaluation the performance of land-air robots. A series of 
                              comparisons and experiments were conducted to demonstrate the robustness and reliability of the proposed 
                              structure in complex field environments.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://arxiv.org/pdf/2210.16875.pdf" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/THU-MIR/Deformable-Aerial-Ground-Platform" target="_blank">Code</a></div>
                <div class="dropdown"><span></span><a href="https://www.youtube.com/watch?v=kGzKuHy6CmA" target="_blank">Video</a></div>
            </aside>
        </div>

        <br>

        <!-- 2023tmech  -->
        <div onmouseout="tmech_stop()" onmouseover="tmech_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="tmech_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2023tmech.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2023tmech.jpg" width="100%" height="100%">
                </div>
                <script type="text/javascript">
                    function tmech_start() {
                    document.getElementById('tmech_image').style.opacity = "1";
                    }

                    function tmech_stop() {
                    document.getElementById('tmech_image').style.opacity = "0";
                    }
                    tmech_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Coupled Modeling and Fusion Control for a Multi-modal Deformable Land-air Robot </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=gVuaz7QAAAAJ" target="_blank">Yuanhao Huang</a>, 
                    <b>Kangyao Huang</b><ion-icon name="mail-outline"></ion-icon>, 
                    <a style="color: #999;">Ziqi Zhao</a>, 
                    <a style="color: #999;">Jingwei Li</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>, 
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> Submitted to RAS </em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://github.com/THU-MIR/Deformable-Aerial-Ground-Platform" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            This paper introduces a structure-deformable land-air robot which possesses both excellent ground driving 
                            and flying ability, with smooth switching mechanism between two modes. The elaborate coupled dynamics model 
                            of the proposed robot is established, including rotors, chassis, especially the deformable structures. 
                            Furthermore, taking fusion locomotion and complex near-ground situations into consideration, a model based 
                            controller is designed for landing and mode switching under various harsh conditions, in which we realise the 
                            cooperation between fused two motion modes. The entire system is implemented in ADAMS/Simulink simulation and 
                            in practical. We conduct experiments under various complex scenarios. The results show our robot can 
                            accomplish land-air switching swiftly and smoothly, and the designed controller can effectively improve the 
                            landing flexibility and reliability.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://arxiv.org/pdf/2211.04185.pdf" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/THU-MIR/Deformable-Aerial-Ground-Platform" target="_blank">Code</a></div>
            </aside>
        </div>
        <br>
        <br>

        <!-- 2023icuas  -->
        <div onmouseout="icuas_stop()" onmouseover="icuas_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="icuas_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2023ICUAS.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2023ICUAS.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function icuas_start() {
                    document.getElementById('icuas_image').style.opacity = "1";
                    }

                    function icuas_stop() {
                    document.getElementById('icuas_image').style.opacity = "0";
                    }
                    icuas_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Path Planning for Air-Ground Robot Considering Modal Switching Point Optimization </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a style="color: #999;">Xiaoyu Wang</a>,
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a style="color: #999;">Honglin Sun</a>, 
                    <a style="color: #999;">Wenzhuo Liu</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>, 
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> International Conference on Unmanned Aircraft Systems (<b>ICUAS</b>) 2023 </em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://github.com/THU-MIR/ABAS_matlab" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            An innovative sort of mobility platform that can both drive and fly is the air-ground robot. 
                            The need for an agile flight cannot be satisfied by traditional path planning techniques for 
                            air-ground robots. Prior studies had mostly focused on improving the energy efficiency of paths, 
                            seldom taking the seeking speed and optimizing take-off and landing places into account. A robot for the 
                            field application environment was proposed, and a lightweight global spatial planning technique for the 
                            robot based on the graph-search algorithm taking mode switching point optimization into account, with an 
                            emphasis on energy efficiency, searching speed, and the viability of real deployment. The fundamental 
                            concept is to lower the computational burden by employing an interchangeable search approach that combines 
                            planar and spatial search. Furthermore, to safeguard the health of the power battery and the integrity of 
                            the mission execution, a trap escape approach was also provided. Simulations are run to test the 
                            effectiveness of the suggested model based on the field DEM map. The simulation results show that our 
                            technology is capable of producing finished, plausible 3D paths with a high degree of believability. 
                            Additionally, the mode-switching point optimization method efficiently identifies additional acceptable 
                            places for mode switching, and the improved paths use less time and energy.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://arxiv.org/pdf/2305.08178.pdf" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/THU-MIR/ABAS_matlab" target="_blank">Code</a></div>
            </aside>
        </div>
        <br>

        <!-- 2023中国科学  -->
        <div onmouseout="scichina_stop()" onmouseover="scichina_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="scichina_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2023scichina.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2023scichina.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function scichina_start() {
                    document.getElementById('scichina_image').style.opacity = "1";
                    }

                    function scichina_stop() {
                    document.getElementById('scichina_image').style.opacity = "0";
                    }
                    scichina_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle">智能飞行汽车关键技术及发展趋势 - State-of-the-art and Technical Trends of Intelligent Flying Cars</h2>
                <h3 class="sectionContentSubTitle">
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a style="color: #999;">Songsong Rong</a>,
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>,
                    <a href="https://www.cae.cn/cae/html/main/colys/00679747.html" target="_blank">Deyi Li</a>,
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=gVuaz7QAAAAJ" target="_blank">Yuanhao Huang</a>, 
                    <b>Kangyao Huang</b>
                    <!-- <a href="https://scholar.google.com.hk/citations?user=pKCG3T8AAAAJ" target="_blank">Jianxi Luo</a>, -->
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> 中国科学:技术科学, Science China-Technological Sciences, 2023</em>
                    <a style="color: rgb(247, 121, 175);font-weight: bold;font-style: oblique;font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">Cover Paper</a>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            城市立体交通是未来智慧出行发展的热点方向, 近年来受到了广泛的关注. 作为城市立体交通的载体, 智能飞行汽车融合了飞机与汽车两种运动模态, 
                            能够灵活地在空中与地面进行切换. 本文介绍了智能飞行汽车 的背景、历史与现状、阐述了其与城市空中交通载具的区别，分析与讨论了飞行汽车的系统设计，
                            并介绍了智 能飞行汽车的关键技术创新，包括动力技术和机电总体设计、多模态切换、模块复用与飞车脑认知等。重点讨 论了飞行汽车的智能化技术，
                            包括近地感知、决策与规划、智能控制与智能通信系统的关键技术与瓶颈. 最后, 结 合现有技术, 对智能飞行汽车的技术进行了剖析, 
                            并讨论了潜在的解决方案与发展趋势.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://www.sciengine.com/SST/doi/10.1360/SST-2023-0098" target="_blank">Paper</a></div>
            </aside>
        </div>
        <br>


        <!-- 2022tiv  -->
        <div onmouseout="tiv_stop()" onmouseover="tiv_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="tiv_image">
                        <video  width="100%" muted="" autoplay="" loop="">
                            <source src="material/2022tiv.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2022tiv.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function tiv_start() {
                    document.getElementById('tiv_image').style.opacity = "1";
                    }

                    function tiv_stop() {
                    document.getElementById('tiv_image').style.opacity = "0";
                    }
                    tiv_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Intelligent Amphibious Ground-aerial Vehicles: State of the Art Technology for Future Transportation </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a style="color: #999;">Jiangeng Huang</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=gVuaz7QAAAAJ" target="_blank">Yuanhao Huang</a>, 
                    <b>Kangyao Huang</b><ion-icon name="mail-outline"></ion-icon>, 
                    <a href="https://scholar.google.com.hk/citations?user=EUnI2nMAAAAJ" target="_blank">Lei Yang</a>, 
                    <a style="color: #999;">Yan Han</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=kLTnwAsAAAAJ" target="_blank">Li Wang</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=pKCG3T8AAAAJ" target="_blank">Jianxi Luo</a>, 
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> IEEE Transactions on Intelligent Vehicles (<b>T-IV</b>) 2022</em> 
                    <em></em>
                    <a style="color: rgb(247, 121, 175);font-weight: bold;font-style: oblique;font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">IF: 14</a>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            Amphibious ground-aerial vehicles fuse flying and driving modes to enable more flexible air-land 
                            mobility and have received growing attention recently. By analyzing the existing amphibious vehicles, 
                            we highlight the autonomous fly-driving functionality for the effective uses of amphibious vehicles in 
                            complex three-dimensional urban transportation systems. We review and summarize the key enabling 
                            technologies for intelligent flying-driving in existing amphibious vehicle designs, identify major 
                            technological barriers and propose potential solutions for future research and innovation. This paper 
                            aims to serve as a guide for research and development of intelligent amphibious vehicles for urban 
                            transportation toward the future.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://arxiv.org/pdf/2207.11384.pdf" target="_blank">Paper</a></div>
            </aside>
        </div>
        <br>

        <!-- 2021ciac  -->
        <div onmouseout="ciac_stop()" onmouseover="ciac_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="ciac_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2021CIAC.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2021CIAC0.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function ciac_start() {
                    document.getElementById('ciac_image').style.opacity = "1";
                    }

                    function ciac_stop() {
                    document.getElementById('ciac_image').style.opacity = "0";
                    }
                    ciac_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Bio-inspired Multi-agent Model and Optimization Strategy for Collaborative Aerial Transport </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=j63_EA0AAAAJ" target="_blank">Jingyu Chen</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=W7ePGWYAAAAJ" target="_blank">John Oyekan</a><ion-icon name="mail-outline"></ion-icon>, 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a> 
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> Chinese Intelligent Automation Conference (<b>CIAC</b>) 2021 </em>
                    <a style="color: rgb(247, 121, 175);font-weight: bold;font-style: oblique;font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">Best Student Paper</a>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            Collaboration between robots provides solutions for transporting more complex and heavier loads. 
                            In this work, inspired by the ant colony foraging and transport, we put forward two collaborative models, 
                            Coupled-Carriers and Navigator-Carrier, for aerial cooperative transport. To achieve this, a linear quadratic 
                            regulator (LQR) is applied to optimize the performance. The results show the task of dual-drone transport 
                            of a bar load is successfully accomplished.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://eprints.whiterose.ac.uk/176758/1/Bio-inspired%20Multi-agent%20Model%20and%20Optimization%20Strategy%20for%20Collaborative%20Aerial%20Transport.pdf" target="_blank">Paper</a></div>
            </aside>
        </div>
        <br>

        <!-- 2023swevo  -->
        <div onmouseout="swevo_stop()" onmouseover="swevo_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="swevo_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2021SWEVO.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2021SWEVO.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function swevo_start() {
                    document.getElementById('swevo_image').style.opacity = "1";
                    }

                    function swevo_stop() {
                    document.getElementById('swevo_image').style.opacity = "0";
                    }
                    swevo_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Decentralised Aerial Swarm for Adaptive and Energy Efficient Transport of Unknown Loads </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=j63_EA0AAAAJ" target="_blank">Jingyu Chen</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=W7ePGWYAAAAJ" target="_blank">John Oyekan</a><ion-icon name="mail-outline"></ion-icon> 
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em>Swarm and Evolutionary Computation (<b>SWEVO</b>) 2021 </em>
                    <a style="color: rgb(247, 121, 175);font-weight: bold;font-style: oblique;font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">IF: 8.2</a>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://github.com/KJaebye/Drone-Swarm-Cooperative-Transport" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            Cooperative transport by a swarm of Quadcopters offers more flexibility and performance when carrying loads 
                            that are complex in structural profile and mass. Ensuring that team members of the swarm are optimally placed 
                            on these loads as well as able to resist disturbances from the environment during transport are current 
                            research challenges. In this paper, we present a decentralized behaviour based subsumption architecture for 
                            enabling a swarm of Quadcopters to explore an unfamiliar area, find a load and transport it to a target 
                            location cooperatively. In the architecture, three behaviours were used: an obstacle avoidance behaviour to 
                            avoid collisions with objects in the environment, a flocking behaviour to ensure swarm structure and a 
                            bacterium behaviour for exploration of the environment and to adapt to the mass profile of various detected 
                            loads.<br><br>

                            By adapting to the mass profile of a detected load, we show that our architecture ensures even energy 
                            distribution among Quadcopters while achieving robustness to disturbances from the environment. Our results 
                            show that a mass adapting swarm is able to conserve energy during payload transportation when compared to a 
                            swarm that does not adapt to a load's profile. Furthermore, we do not use explicit communication between team 
                            members but instead rely on data from visual sensors attached to the Quadcopters. We experiment with 
                            simulations in a physics informed robot simulator called CoppeliaSim and demonstrate the effectiveness of our 
                            architecture when utilized for cooperative transport of irregular loads.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="publications/2021_SWEVO_Decentralised aerial swarm for adaptive and energy efficient transport of unknown loads.pdf" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/KJaebye/Drone-Swarm-Cooperative-Transport" target="_blank">Code</a></div>
            </aside>
        </div>

        <br><br>
	</section>

    <!-- Projects -->
    <section class="section2">
        <h2 class="sectionTitle">Projects</h2>
        <!-- <hr class="sectionTitleRule"> -->
        <hr class="sectionTitleRule2">

        <!-- flyingcar  -->
        <div onmouseout="flyingcar_stop()" onmouseover="flyingcar_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="flyingcar_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/flyingcar.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <aside class="externalResourcesNav" style="margin-top:0%">
                            <div class="dropdown">
                                <span></span><a href="https://mp.weixin.qq.com/s/u-WIZV_5p_Ua6ohFrNEB9Q" target="_blank">News</a>
                            </div>
                            <div class="dropdown"><span></span><a href="https://www.bilibili.com/video/BV1gN4y1a72Z/" target="_blank">Video</a></div>
                        </aside>
                    </div>
                    <img src="material/flyingcar.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function flyingcar_start() {
                    document.getElementById('flyingcar_image').style.opacity = "1";
                    }

                    function flyingcar_stop() {
                    document.getElementById('flyingcar_image').style.opacity = "0";
                    }
                    flyingcar_stop()
                </script>
                
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> the Implementation of Flying Car for Ground-aerial Transportation</h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Partners:</b>
                    <a style="font-style: italic;font-size: 10px;" href="http://www.svm.tsinghua.edu.cn/">@School of Vehicle and Mobility, THU</a>
                    <a style="font-style: italic;font-size: 10px;" href="https://www.cs.tsinghua.edu.cn/">@Department of Computer Science and Technology, THU</a>
                    <a style="font-style: italic;font-size: 10px;" href="https://www.tsari.tsinghua.edu.cn/">@Suzhou Automobile Research Institute-CN</a>
                    <a style="font-style: italic;font-size: 10px;" href="https://www.sutd.edu.sg/">@Singapore University of Technology and Design</a>
                    <a style="font-style: italic;font-size: 10px;" href="https://www.81uav.cn/com/bingouav/">@Bingo Intelligence Co., Ltd.</a>
                    <a style="font-style: italic;font-size: 10px;" href="http://www.fullymax.com/">@Fullymax Co., Ltd.</a>
                    <a style="font-style: italic;font-size: 10px;" href="http://www.xy-uav.com/">@XY-UAV Co., Ltd.</a>
                    <a style="font-style: italic;font-size: 10px;" href="https://www.robosense.cn/index">@RoboSense Co., Ltd.</a>
                </h3>
                <h3 class="sectionContentSubTitle"> 
                    Project Principal:
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    Project Technical Leader:
                    <b>Kangyao Huang</b>,
                    Director:
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>                    
                </h3>
                <h3 class="sectionContentSubTitle">
                    <a style="font-size: 12px;">Other participants: </a>
                    <a style="font-size:9px; line-height: 3px;">Qihao Zhu, Qingjing Meng, Bo Cui, Songsong Rong, Haowen Shen, Guole Li, Huaping Liu, Jianxi Luo, Dafeng Jin, 
                        Jun Yang, Shuzhi Ge, Weiguo Yang, Yu Wan, Zhiqiang Yang, Zhenlong Ding, Xiaofeng Xu, Jiang Qian, Chaoyang Ha, Yuanhao Huang, Qiujiang Wu, Xingang Wu, Qifan Tan, Mo Zhou, Yang Shen, Li Wang, Yan Han, Zhaosheng Huang, Zhiwei Li, Lei Yang, Linxun Shi, Dazhong Xu, Kai Tang, et cetera.</a>
                </h3>
                <p style="font-size: 10px;color: rgb(135, 4, 187);">We successfully developed the first generation of Tsinghua Mengshi intelligent flying car. This vehicle is the world's first pure electric rotorcraft unmanned flying vehicle with integrated intelligent driving function.
                </p>
            </section>
        </div>
        <br>

        <!-- 2021ad  -->
        <div onmouseout="ad_stop()" onmouseover="ad_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="ad_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2021ad.png" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2021ad.png" width="100%">
                </div>
                <script type="text/javascript">
                    function ad_start() {
                    document.getElementById('ad_image').style.opacity = "1";
                    }

                    function ad_stop() {
                    document.getElementById('ad_image').style.opacity = "0";
                    }
                    ad_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Autonomous Driving Architecture towards SCSTSV </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Director:</b>
                    <a style="color: #999;">Qifan Tan</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>
                    <a style="font-style: italic;">@New Technology Concept Vehicles, THU</a>
                </h3>
                <p style="font-size: 10px;"><b>Brief:</b> Towards the Smart City-Smart Transportation-Smart Vehicles(SCSTSV), we focus on the key areas of autonomous 
                    driving technology, particularly in the design and optimization of architectures for perception, decision-making, 
                    and control. I propose a comprehensive architecture that integrates perception, decision-making, and control into a unified framework, further enhancing 
                    system performance through the integration of road testing equipment.</p>
            </section>
        </div>
        <br>

        <!-- solar-uav  -->
        <div onmouseout="solar_stop()" onmouseover="solar_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="solar_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/solar-uav.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/solar-uav.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function solar_start() {
                    document.getElementById('solar_image').style.opacity = "1";
                    }

                    function solar_stop() {
                    document.getElementById('solar_image').style.opacity = "0";
                    }
                    solar_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Solar-powered UAV for Long Duration Cruising</h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Work with</b>
                    <a style="color: #999;">Colleagues </a><a style="font-style: italic;">@Bingo Intelligence Co., Ltd.</a>
                </h3>
                <p style="font-size: 10px;"><b>Brief:</b> This research focused on enhancing the endurance of solar-powered unmanned aerial vehicles (UAVs). A key aspect of the study involved redesigning the aerodynamic shape to improve efficiency. Additionally, our team developed a dynamic power system with low vortex drag variable-pitch propellers to adapt to varying wind speeds during flight, enabling them to operate efficiently across diverse conditions. This research contributes to the advancement of renewable energy-powered UAV technology, offering potential applications in various fields such as environmental monitoring, aerial photography, and telecommunications.</p>
                <p style="font-size: 10px;color: rgba(1, 145, 193, 0.579);">
                We honor the memory of Zhaoxi Wang, one of co-founders of the team, whose dedication and vision continue to inspire us as we move forward, and his spirit will forever remain an integral part of our journey,just like his aircraft did.
                </p>
            </section>
        </div>
        <br>

        <!-- auto-patrolling  -->
        <div onmouseout="patrolling_stop()" onmouseover="patrolling_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="patrolling_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/auto-patrolling.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/auto-patrolling.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function patrolling_start() {
                    document.getElementById('patrolling_image').style.opacity = "1";
                    }

                    function patrolling_stop() {
                    document.getElementById('patrolling_image').style.opacity = "0";
                    }
                    patrolling_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Auto-Patralling UAV Platform</h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Work with</b> 
                    <a style="color: #999;">Colleagues </a><a style="font-style: italic;">@Bingo Intelligence Co., Ltd.</a>
                </h3>
                <p style="font-size: 10px;"><b>Brief:</b> This project focused on the development of an autonomous inspection drone 
                    system for airports. This project encompassed the overall design of the airport system and the design and production 
                    of electromechanical controls. We prioritized the autonomous inspection functionality of the drones. Through a 
                    comprehensive approach balancing airport safety and efficiency, we devised a complete system including structural 
                    design of the drones, development of electromechanical control systems, and optimization of inspection algorithms. 
                    This system not only enables comprehensive inspection of airport facilities but also autonomously responds to and 
                    alerts to anomalies.</p>
            </section>
        </div>
        <br>
        
        <!-- oil-drone  -->
        <div onmouseout="oil_stop()" onmouseover="oil_start()">
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="oil_image">
                        <video  width="100%" muted="" autoplay="" loop="">
                            <source src="material/oil-drone.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/oil-drone.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function oil_start() {
                    document.getElementById('oil_image').style.opacity = "1";
                    }

                    function oil_stop() {
                    document.getElementById('oil_image').style.opacity = "0";
                    }
                    oil_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Oil-powered Variable-pitch Quadrotor</h2>
                <p style="font-size: 10px;"><b>My dissertation for BEng degree.</b> Notably, this is the <b>first successful flight</b> of oil-powered rotary-wing UAV utilizing variable-pitch control in China. We finished it at the end of 2015. Work with teammates Fanjie Kong, Jingdong Ma.</p>
                <p style="font-size: 10px;"><b>Brief:</b> I participated a groundbreaking project focused on the development of a 
                oil-powered variable-pitch multirotor unmanned aerial vehicle (UAV). This project involved the comprehensive 
                design and prototyping testing of the UAV. Our efforts encompassed the integration of advanced variable-pitch 
                technology with traditional oil-powered UAV systems, leading to a novel and efficient aerial platform. We use 
                gears and belts as the power transmission method, where belts can effectively reduce the vibrations generated 
                by the engine. The successful flight testing signifies a significant milestone in the domestic UAV industry, showcasing the feasibility and potential of variable-pitch control in enhancing the performance and 
                versatility of oil-powered UAVs. </p>
            </section>
        </div>

    </section>
    <br>

    <!-- Education -->
    <section class="section2">
        <h2 class="sectionTitle">Education</h2>
        <hr class="section2">

        <div class="section2" style="padding:0px;vertical-align:middle;line-height: 10px;">
            <group>
                <img src="profile/清华logo.png" width="3%" height="3%">
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;2022~now,&emsp;</p>
                <p>
                    <a style="font-weight: bold; font-size: 11px;">PhD</a> candidate in Computer Science and Technology, <a style="font-weight: bold; font-size: 11px;">Tsinghua University</a>, China
                </p>
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;Dissertation:&emsp;</p><p style="font-style: italic; font-size: 11px;"> Robot Interactive Learning</p>
            </group>
            <group>
                <img src="profile/UoS.jpg" width="3%" height="3%">
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;2019~2020,&emsp;</p>
                <p>
                    <a style="font-weight: bold; font-size: 11px;">MRes</a> in Control & Systems Engneering, <a style="font-weight: bold;color: rgb(4, 113, 222); font-size: 11px;" href="https://www.sheffield.ac.uk/acse">ACSE</a>, <a style="font-weight: bold; font-size: 11px;">the University of Sheffied</a>, UK
                </p>
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;Dissertation:&emsp;</p><p style="font-style: italic; font-size: 11px;">Cooperative Transport by Swarm Robots</p>
            </group>
            <group>
                <img src="profile/西工大校标大图 蓝白版.jpg" width="3%" height="3%">
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;2012~2016,&emsp;</p>
                <p>
                    <a style="font-weight: bold; font-size: 11px;">BEng</a> in Aircraft Design, <a style="font-weight: bold;color: rgb(1, 98, 195); font-size: 11px;" href="https://hangtian.nwpu.edu.cn/">School of Astronautics</a>, <a style="font-weight: bold; font-size: 11px;">Northwestern Polytechnical University</a>, China
                </p>
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;Dissertation:&emsp;</p><p style="font-style: italic; font-size: 11px;">Oil-powered Quadrotor</p>
            </group>
        </div>

    </section>

    <br>
    <!-- Experiences -->
    <section class="section2">
        <h2 class="sectionTitle">Experiences</h2>
        <hr class="section2">

        <div class="section2" style="padding:0px;vertical-align:middle;line-height: 5px;">
            <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2015~2019,&emsp;</h3>
                <h3 class="sectionContentSubTitle">
                    <a style="font-weight: bold;">Co-Founder</a> @<a style="font-weight: bold;color: rgb(112, 112, 112);">Bingo Intelligence Co. Ltd.</a>, Xi'an, ShaanXi, China.
                </h3>
            </group>
            <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2020~2022,&emsp;</h3>
                <h3 class="sectionContentSubTitle">
                    <a style="font-weight: bold;">Research assistant</a> @Institute for New Technology Concept Vehicles,<a style="font-weight: bold;color: rgb(113, 112, 114);"> THU</a>, Beijing, China
                </h3>
            </group>
            <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2023~now,&emsp;</h3>
                <h3 class="sectionContentSubTitle">
                    <a style="font-weight: bold;">Founder</a> <a>@超微智导技术</a></a>, China
                </h3>
            </group>
        </div>

    </section>
    <br><br>

	  
  <hr>
  
</section>

<footer>
  <p class="footerDisclaimer">Updated by KJaebye<span></span></p>
  <p class="footerNote"></p>
</footer>

<script type="module" src="https://unpkg.com/ionicons@7.1.0/dist/ionicons/ionicons.esm.js"></script>
<script nomodule src="https://unpkg.com/ionicons@7.1.0/dist/ionicons/ionicons.js"></script>

</body>
</html>
