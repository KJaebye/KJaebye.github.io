<!doctype html>
<html>
<head>

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Kangyao Huang</title>
<link href="styles/aboutPageStyle.css" rel="stylesheet" type="text/css">
<link rel="icon" href="./profile/ride.jpg"><style type="text/css">
</style>

</head>

<body alink = "#282727" vlink = "#9b9b9b" link = "#9b9b9b">
<!-- Header content -->
<header>
    <div class="profilePhoto"> 
        <img src="profile/hky_avatar.jpg" alt="sample" width="200">
        <!-- <img src="profile/hky.jpg" alt="sample" width="200"> -->
        <!-- <img src="profile/hky_life.jpg" alt="sample" width="200"> -->
    </div>
    <!-- Identity details -->
    <section class="profileHeader">
        <h1 style="line-height: 30px;font-size: 28px;margin-bottom: auto;">Kangyao Huang&emsp;&emsp;<img src="profile/name.png" width="80" style="margin-bottom: -5px;"></h1>
        <h3>PhD Candidate | Physical AI Researcher | Aerospace Engineer</h3>
        <hr>
        <p style="line-height: 15px;font-size: 12px;margin-bottom: auto;">I am Kangyao Huang (黄康尧 in Chinese) from China, working towards physical AI and robotics research and application. Currently, I am pursuing a PhD degree in Computer Science at <a style="color:#6e02ba" href="https://www.tsinghua.edu.cn/">Tsinghua University(THU)</a> under the supervision of Prof. <a href="https://sites.google.com/site/thuliuhuaping">Huaping Liu</a>, working closely with Prof. <a href="https://www.au.tsinghua.edu.cn/info/1111/1524.htm">Xiangyang Ji</a>, and focusing on robot learning, especially embodied interactive learning in simulation and Sim2Real policy transfer in reality.
            Besides, I also hold an MRes degree in Robotics from <a style="color: rgb(5, 103, 196);" href="https://www.sheffield.ac.uk/acse">ACSE</a>, <a style="color: rgb(5, 103, 196);" href="https://www.sheffield.ac.uk/">the University of Sheffield(UoS)</a>, UK., supervised by Prof. <a href="https://scholar.google.co.uk/citations?user=W7ePGWYAAAAJ&hl=en">John Oyekan</a>, and a BEng degree in Aerospace from <a style="color: rgb(25, 74, 179);" href="https://www.nwpu.edu.cn/">Northwestern Polytechnical University (NWPU)</a>, China. I had several years start-up experience in aerospace and robotics sectors, serving as CEO, technical director, and robotics engineer.
            <br>
            <br> I also have experience in EAI, UAV, and autonomous driving. I led the development of the second/third generation of Tsinghua Mengshi flying car which is <b>the world's first electric manned rotorcraft ground-aerial vehicle</b> with integrated intelligent driving function. My current research interest is in Embodied AI for virtual and real world practice. I also follow ideas on aerial robotics and reconstruction. I am doing a startup @emNavi Tech, focusing on the EAI enhanced navigation and related sensors. If you have any ideas, please do not hesitate to email me directly.<br></p>
    </section>
    <aside class="socialNetworkNavBar">
        <div class="socialNetworkNav"> 
            <a href="mailto:kangyao.huang@outlook.com">
                <img src="profile/mail.png"  alt="sample" width="30" ></a>
        </div>
        <div class="socialNetworkNav">
            <a href="https://github.com/kjaebye" target="_blank">
                <img src="profile/github.png" alt="sample" width="30"></a>
        </div>
        <div class="socialNetworkNav"> 
            <a href="https://scholar.google.com/citations?user=df7fnwQAAAAJ" target="_blank">
                <img src="profile/scholar.png"  alt="sample" width="30"></a>
        </div>
        <div class="socialNetworkNav">
            <a href="" target="_blank">
                <img src="profile/linkedin.png"  alt="sample" width="30"></a>
        </div>
        <div class="socialNetworkNav">
            <a href="https://orcid.org/0000-0002-5708-2620" target="_blank">
                <img src="profile/orcid.png"  alt="sample" width="30"></a>
        </div>
        <div class="socialNetworkNav">
            <a href="https://www.xiaohongshu.com/user/profile/638ceaa1000000001f01ce42" target="_blank">
                <img src="profile/xhs.png"  alt="sample" width="30"></a>
        </div>
    </aside>
</header>

<section class="mainContent"> 
    <section class="section2">
        <h2 class="sectionTitle">Top Open-source Projects</h2>
        <!-- <hr class="sectionTitleRule"> -->
        <hr class="sectionTitleRule2">

    <!-- AirGym-Sim  -->
    <div onmouseout="airgym_sim_stop()" onmouseover="airgym_sim_start()">	  
        <div class="sectionContent" style="padding:0px;vertical-align:middle">
            <div class="one">
                <div class="two" id="airgym-sim_image">
                    <video  width="100%" height="100%" muted="" autoplay="" loop="">
                        <source src="material/airgym-sim.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <img src="material/airgym-sim.png" width="100%">
            </div>
            <script type="text/javascript">
                function airgym_sim_start() {
                document.getElementById('airgym-sim_image').style.opacity = "1";
                }

                function airgym_sim_stop() {
                document.getElementById('airgym-sim_image').style.opacity = "0";
                }
                airgym_sim_stop()
            </script>
        </div>
        <section class="section2Content">
            <h2 class="sectionContentTitle"> <img src="material/airgym-logo.png" alt="emNavi" style="height: 30px; vertical-align: middle;"> Quadrotor DRL Simulation Platform  </h2>
                <p style="font-size: 12px;"><b>AirGym</b> is an open souce Python quadrotor simulator based on IsaacGym, a part of AirGym series Sim-to-Real working flow. It provides a high-fidelity dynamics and Deep Reinforcement Learning (DRL) framework for quadrotor robot learning research. Furthermore, we also provide toolkits for transferring policy from AirGym simulator to the real quadrotor emNavi-X152b, making Sim-to-Real possible.  </p>
            </h2>

        </section>
        <aside class="externalResourcesNav" style="margin-top:0%"> 
            <div class="dropdown">
                <span></span><a href="https://github.com/emNavi/AirGym" target="_blank">Github</a>
            </div>
            <div class="dropdown">
                <span></span><a href="https://emnavi.tech/AirGym/" target="_blank">Project Page</a>
            </div>
        </aside>
    </div>
    <br>


</section>

<section class="mainContent"> 
    <section class="section2">
        <h2 class="sectionTitle">Book</h2>
        <!-- <hr class="sectionTitleRule"> -->
        <hr class="sectionTitleRule2">

        <!-- Book Content -->
        <div class="book-container">
            <div class="book-cover">
                <img src="material/book_springer.png" alt="cover" class="book-image">
            </div>
            <div class="book-info"> 
                <h3 class="sectionContentTitle">
                    <a href="https://link.springer.com/book/10.1007/978-981-96-5871-8">Embodied Multi-Agent Systems</a>
                </h3>
                <h3 class="sectionContentSubTitle" style="font-size: 11px;"> 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>,
                    <a href="" target="_blank">Xinzhu Liu</a>,
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=OCauNHUAAAAJ" target="_blank">Di Guo</a>
                </h3>
                <p class="book-summary;" style="font-size: 11px;">
                    This book focuses on active perception and interactive learning for embodied multi-agent systems. The remarkable reasoning, perception, and decision-making capabilities demonstrated by LLM in recent years have brought significant opportunities for the exploration of artificial general intelligence (AGI). This results in the development of increasingly larger models and a higher consumption of data. The ultimate goal is to achieve AGI through a unified brain model. However, when it comes to embodied agents, this strategy encounters considerable challenges due to the variety in morphology and function among these agents. It is neither feasible nor desirable to expect all embodied agents to conform to a single morphology. Instead, we should embrace the principles of biodiversity, promoting the existence, collaboration, and interaction of various forms. This recognition has motivated our research into embodied multi-agent systems. During this process, we have realized that active perception, along with the interactive learning capabilities that stem from it, plays a crucial role in fostering collaboration and synergy among multiple embodied agents.
                </p>
                <p style="font-size: 10px;color: rgba(141, 20, 139, 0.579);">
                    We would like to thank Prof. Angelo Cangelosi, Prof. David Hsu, Prof. John Aloimonos who provide lots of support. We would like to express our gratitude to Dr. Hongbo Li from Geek+ and Dr. Tianlei Zhang from TrunkTech for their invaluable support in our study of embodied multi-agent collaboration. Additionally, we would like to express our sincere gratitude to Chenxu Wang, Xinghang Li, Juan Wang, Peiyan Li, Pingcheng Jian, and Chuye Hong for their significant assistance in preparing the figures and proofreading the book.
                </p>
            </div>
        </div>

    </section>
</section>
<style>
    .book-container {
        display: flex;
        margin-top: 20px;
        gap: 30px;
    }
    
    .book-cover {
        flex: 0 0 160px;
    }
    
    .book-image {
        width: 100%;
        height: auto;
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    
    .book-info {
        flex: 1;
    }
    
    .book-title {
        color: #333;
        margin-bottom: 15px;
        font-size: 1.5em;
    }
    
    .book-summary {
        line-height: 1.6;
        color: #555;
    }
</style>

<!-- content -->
<section class="mainContent"> 
    <section class="section2">
        <h2 class="sectionTitle">Selected Publications</h2>
        <!-- <hr class="sectionTitleRule"> -->
        <hr class="sectionTitleRule2">

        <!-- longfly -->
        <!-- <div onmouseout="longfly_stop()" onmouseover="longfly_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="longfly_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/longfly.png" width="100%" height="100%">
                </div>
                <script type="text/javascript">
                    function longfly_start() {
                    document.getElementById('longfly_image').style.opacity = "1";
                    }

                    function longfly_stop() {
                    document.getElementById('longfly_image').style.opacity = "0";
                    }
                    longfly_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> LongFly: Long-Horizon UAV Vision-and-Language Navigation with Spatiotemporal Context Integration </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a>Wen Jiang</a>,
                    <a>Li Wang</a>,
                    <b>Kangyao Huang</b>, 
                    <a>Wei Fan</a>,
                    <a>Jinyuan Liu</a>,
                    <a>Shaoyu Liu</a>,
                    <a>Hongwei Duan</a>,
                    <a>Bin Xu</a>,
                    <a>Xiangyang Ji</a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> Submitted to TGRS 2026</em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%">
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px;">
                            Unmanned aerial vehicles (UAVs) are crucial tools
                            for post-disaster search and rescue, facing challenges such as high
                            information density, rapid changes in viewpoint, and dynamic
                            structures, especially in long-horizon navigation. However, cur-
                            rent UAV vision-and-language navigation(VLN) methods strug-
                            gle to model long-horizon spatiotemporal context in complex
                            environments, resulting in inaccurate semantic alignment and
                            unstable path planning. To this end, we propose LongFly, a
                            spatiotemporal context modeling framework for long-horizon
                            UAV VLN. LongFly proposes a history-aware spatiotemporal
                            modeling strategy that transforms fragmented and redundant
                            historical data into structured, compact, and expressive repre-
                            sentations. First, we propose the slot-based historical image com-
                            pression module, which dynamically distills multi-view historical
                            observations into fixed-length contextual representations. Then,
                            the spatiotemporal trajectory encoding module is introduced to
                            capture the temporal dynamics and spatial structure of UAV
                            trajectories. Finally, to integrate existing spatiotemporal context
                            with current observations, we design the prompt-guided multi-
                            modal integration module to support time-based reasoning and
                            robust waypoint prediction. Experimental results demonstrate that LongFly outperforms state-of-the-art UAV VLN baselines by 7.89% in Success Rate (SR) and 6.33% in Success weighted by Path Length (SPL), consistently across both seen and unseen environments.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="" target="_blank">Code</a></div>
            </aside>
        </div>
        <br> -->

        <!-- ActiveEventNet+ -->
        <!-- <div onmouseout="activeEventNet_stop()" onmouseover="activeEventNet_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="activeEventNet_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2026pami.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2026pami.png" width="100%" height="100%">
                </div>
                <script type="text/javascript">
                    function activeEventNet_start() {
                    document.getElementById('activeEventNet_image').style.opacity = "1";
                    }

                    function activeEventNet_stop() {
                    document.getElementById('activeEventNet_image').style.opacity = "0";
                    }
                    activeEventNet_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Towards Ultrafast Depth Sensing Via Active Event-based Stereo Vision </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a>Jianing Li</a>,
                    <a>Yunjian Zhang</a>,
                    <a>Haiqian Han</a>,
                    <b>Kangyao Huang</b>, 
                    <a>Xiangyang Ji</a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> Submitted to TPAMI 2026</em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%">
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px;">
                            Conventional frame-based imaging for active stereo systems has encountered major challenges in fast-motion scenarios.
                            However, how to design a novel paradigm for ultra-high-speed depth sensing remains an open issue. In this paper, we propose a novel
                            problem setting, namely active event-based stereo vision, which is the first trial to integrate binocular event cameras and an infrared
                            projector for high-speed dense depth sensing. Technically, we first build a stereo camera prototype system and present a real-world
                            dataset with over 21.5k spatiotemporal synchronized labels at 15 Hz, while also establishing a realistic synthetic dataset with stereo
                            event streams and 23.8k synchronized labels at 20 Hz. Then, we propose ActiveEventNet+, a lightweight yet effective event-based
                            stereo matching neural network that learns to generate high-quality dense disparity maps from stereo event streams with low latency.
                            Our ActiveEventNet+ mainly involves three innovations: incorporating lightweight blocks into event-based stereo matching frameworks,
                            designing a novel cost volume with dynamic interactions between stereo pairs, and presenting an effective temporal consistency
                            architecture to fully use rich temporal cues in event streams. The results show that our ActiveEventNet+ outperforms state-of-the-art
                            methods meanwhile significantly reducing computational complexity. Our solution offers superior depth sensing performance compared
                            to conventional frame-based stereo cameras in high-speed scenes, while also achieving an inference speed of up to 150 FPS with our
                            prototype. We believe that this novel paradigm will provide new insights into future depth sensing systems. Our dataset and code can
                            be available at https://github.com/jianing-li/active_event_based_stereo.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/jianing-li/active_event_based_stereo" target="_blank">Code</a></div>
            </aside>
        </div>
        <br><br> -->

        <!-- ral compet drone-->
        <div onmouseout="competdrone_stop()" onmouseover="competdrone_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="competdrone_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/ral-compet-drone_2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/ral-compet-drone.png" width="100%" height="100%">
                </div>
                <script type="text/javascript">
                    function competdrone_start() {
                    document.getElementById('competdrone_image').style.opacity = "1";
                    }

                    function competdrone_stop() {
                    document.getElementById('competdrone_image').style.opacity = "0";
                    }
                    competdrone_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Competitive Learning for Autonomous Flight </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang*</b>, 
                    <a>Hao Wang*</a>,
                    <a href="https://scholar.google.com.hk/citations?user=OCauNHUAAAAJ" target="_blank">Di Guo</a>, 
                    <a>Xiangkui Zhang</a>,
                    <a>Xiangyang Ji</a>,
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon><br>
                    <a style="font-size: 10px;color: rgb(247, 121, 175);">
                        <b>*</b> contribute equally to this work
                    </a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> IEEE Robotics and Automation Letters (<b>RA-L</b>) 2025</em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%">
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px;">
                            The competition among a swarm often brings about astonishing potential beyond the ordinary. This paper proposes an approach for enhancing autonomous obstacle avoidance in aerial robots through competitive training. By constructing a multi-agent environment, we introduce competition between individuals as a form of comparative learning, stimulating more robust end-to-end flight strategies. Unlike traditional single-agent reinforcement learning (RL) methods, our framework leverages competitive interactions among virtual agents to generate richer training signals, leading to superior performance. Experimental results demonstrate that policies trained in this competitive multi-agent setting outperform those derived from single-drone simulation-based RL, achieving higher efficiency and adaptability in complex environments. Furthermore, ablation studies are conducted to validate the effectiveness and limitations of competitive learning. This work highlights the potential of competitive learning paradigms in advancing autonomous aerial robot navigation.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://ieeexplore.ieee.org/document/11283021" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/emNavi/AirGym" target="_blank">Code</a></div>
            </aside>
        </div>
        <br>

        <!--nature review ee-->
        <div onmouseout="nree_stop()" onmouseover="nree_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="nree_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2025nree_1.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2025nree_1.png" width="100%" height="100%">
                </div>
                <script type="text/javascript">
                    function nree_start() {
                    document.getElementById('nree_image').style.opacity = "1";
                    }

                    function nree_stop() {
                    document.getElementById('nree_image').style.opacity = "0";
                    }
                    nree_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Learning for Embodiment and Embodiment for Learning </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon>,
                    <a href="https://scholar.google.com.hk/citations?user=OCauNHUAAAAJ" target="_blank">Di Guo</a>, 
                    <b>Kangyao Huang</b>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> <b>Nature</b> Reviews Electrical Engineering 2025</em> 
                    <em></em>
                    <a style="color: rgb(247, 121, 175);font-weight: bold;font-style: oblique;font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">Comment Article</a>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%">
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px;">
                            Learning and embodiment are intertwined, resulting in a mutually reinforcing effect. Research should aim not only for learning to enhance embodiment, but also, more importantly, for embodiment to facilitate learning. Achieving synergy between these two aspects remains an ongoing challenge
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://doi.org/10.1038/s44287-025-00203-4" target="_blank">Paper</a></div>
            </aside>
        </div>
        <br><br>

        <!-- airgym-->
        <div onmouseout="airgym_stop()" onmouseover="airgym_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="airgym_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/airgym_2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/airgym_1.png" width="100%" height="100%">
                </div>
                <script type="text/javascript">
                    function airgym_start() {
                    document.getElementById('airgym_image').style.opacity = "1";
                    }

                    function airgym_stop() {
                    document.getElementById('airgym_image').style.opacity = "0";
                    }
                    airgym_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Towards Task-Oriented Flying: Framework, Infrastructure, and Principles </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang*</b>, 
                    <a>Hao Wang*</a>,
                    <a>Jingyu Chen</a>,
                    <a>Jintao Chen</a>,
                    <a>Yu Luo</a>,
                    <a>Di Guo</a>,
                    <a>Xiangkui Zhang</a>,
                    <a>Xiangyang Ji</a>,
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon> 
                    <br>
                    <a style="font-size: 10px;color: rgb(247, 121, 175);">
                        <b>*</b> contribute equally to this work
                    </a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> arXiv</em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%">
                <div class="dropdown">
                    <span></span><a href="https://emnavi.tech/AirGym/" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px;">
                            Deploying robot learning methods to a quadrotor in unstructured outdoor environments is an exciting task. Quadrotors operating in real-world environments by learning-based methods encounter several challenges: a large amount of simulator generated data required for training, strict demands for real-time processing onboard, and the sim-to-real gap caused by dynamic and noisy conditions. Current works have made a great breakthrough in applying learning-based methods to end-to-end control of quadrotors, but rarely mention the infrastructure system training from scratch and deploying to reality, which makes it difficult to reproduce methods and applications. To bridge this gap, we propose a platform that enables the seamless transfer of end-to-end deep reinforcement learning (DRL) policies. We integrate the training environment, flight dynamics control, DRL algorithms, the MAVROS middleware stack, and hardware into a comprehensive workflow and architecture that enables quadrotors' policies to be trained from scratch to real-world deployment in several minutes. Our platform provides rich types of environments including hovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and planning in unknown environments, as a physical experiment benchmark. Through extensive empirical validation, we demonstrate the efficiency of proposed sim-to-real platform, and robust outdoor flight performance under real-world perturbations. Details can be found from our website https://emnavi.tech/AirGym/.

                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/emNavi/AirGym" target="_blank">Code</a></div>
                <div class="dropdown"><span></span><a href="https://emnavi.tech/AirGym/" target="_blank">Video</a></div>
            </aside>
        </div>
        <br>

        <!-- d_hrl-->
        <div onmouseout="d_hrl_stop()" onmouseover="d_hrl_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="d_hrl_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2024dhrl_1.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2024dhrl_1.png" width="100%" height="100%">
                </div>
                <script type="text/javascript">
                    function d_hrl_start() {
                    document.getElementById('d_hrl_image').style.opacity = "1";
                    }

                    function d_hrl_stop() {
                    document.getElementById('d_hrl_image').style.opacity = "0";
                    }
                    d_hrl_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Learning a Distributed Hierarchical Locomotion Controller for Embodied Cooperation </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a>Chuye Hong*</a>,
                    <b>Kangyao Huang*</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon> 
                    <br>
                    <a style="font-size: 10px;color: rgb(247, 121, 175);">
                        <b>*</b> contribute equally to this work
                    </a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em>Conference on Robot Learning (<b>CoRL</b>) 2024</em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%">
                <div class="dropdown">
                    <span></span><a href="https://d-hrl.github.io/" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            In this work, we propose a distributed hierarchical locomotion control strategy for whole-body 
                            cooperation and demonstrate the potential for migration into large numbers of agents. 
                            Our method utilizes a hierarchical structure to break down complex tasks into smaller, 
                            manageable sub-tasks. By incorporating spatiotemporal continuity features, we establish the 
                            sequential logic necessary for causal inference and cooperative behaviour in sequential tasks, 
                            thereby facilitating efficient and coordinated control strategies. Through training within this 
                            framework, we demonstrate enhanced adaptability and cooperation, leading to superior performance in
                             task completion compared to the original methods. Moreover, we construct a set of environments as 
                             the benchmark for embodied cooperation.

                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://proceedings.mlr.press/v270/hong25a.html" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="" target="_blank">Code</a></div>
                <div class="dropdown"><span></span><a href="https://d-hrl.github.io/" target="_blank">Video</a></div>
            </aside>
        </div>
        <br>
        <br>

        <!-- 2024ijcai-->
        <div onmouseout="ijcai24_stop()" onmouseover="ijcai24_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="ijcai24_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2024ijcai_2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2024ijcai.png" width="100%">
                </div>
                <script type="text/javascript">
                    function ijcai24_start() {
                    document.getElementById('ijcai24_image').style.opacity = "1";
                    }

                    function ijcai24_stop() {
                    document.getElementById('ijcai24_image').style.opacity = "0";
                    }
                    ijcai24_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> CompetEvo: Towards Morphological Evolution from Competition </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=OCauNHUAAAAJ" target="_blank">Di Guo</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a style="color: #999;">Xiangyang Ji</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon> 
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em>International Joint Conference
                        on Artificial  Intelligence (<b>IJCAI</b>) 2024 </em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://competevo.github.io/" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            Training an agent to adapt to specific tasks through co-optimization of morphology and control has 
                            gradually attracted attention. However, whether there exists an optimal configuration and tactics for 
                            agents in a multiagent competition scenario is still an issue that is challenging to definitively conclude. 
                            In this context, we propose competitive evolution (CompetEvo), which co-evolves agents' designs and tactics in 
                            confrontation. We build arenas consisting of three animals and their evolved derivatives, placing agents with 
                            different morphologies in direct competition with each other. The results reveal that our method enables agents 
                            to evolve a more suitable design and strategy for fighting compared to fixed-morph agents, allowing them to 
                            obtain advantages in combat scenarios. Moreover, we demonstrate the amazing and impressive behaviors that emerge 
                            when confrontations are conducted under asymmetrical morphs.

                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://dl.acm.org/doi/abs/10.24963/ijcai.2024/10" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/KJaebye/competevo" target="_blank">Code</a></div>
                <div class="dropdown"><span></span><a href="https://competevo.github.io/" target="_blank">Video</a></div>
            </aside>
        </div>
        <br><br>

        <!-- 2024icra-->
        <div onmouseout="icra24_stop()" onmouseover="icra24_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="icra24_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2024icra_2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2024icra.png" width="100%">
                </div>
                <script type="text/javascript">
                    function icra24_start() {
                    document.getElementById('icra24_image').style.opacity = "1";
                    }

                    function icra24_stop() {
                    document.getElementById('icra24_image').style.opacity = "0";
                    }
                    icra24_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Stimulate the Potential of Robots via Competition </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=OCauNHUAAAAJ" target="_blank">Di Guo</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a style="color: #999;">Xiangyang Ji</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon> 
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em>IEEE International Conference on
                        Robotics and Automation (<b>ICRA</b>) 2024 </em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://github.com/KJaebye/Multiagent-Race" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            It is common for us to feel pressure in a competition environment, 
                            which arises from the desire to obtain success comparing with other individuals or opponents. 
                            Although we might get anxious under the pressure, it could also be a drive for us to stimulate our 
                            potentials to the best in order to keep up with others. Inspired by this, we propose a competitive 
                            learning framework which is able to help individual robot to acquire knowledge from the competition, 
                            fully stimulating its dynamics potential in the race. Specifically, the competition information among 
                            competitors is introduced as the additional auxiliary signal to learn advantaged actions. We further 
                            build a Multiagent-Race environment, and extensive experiments are conducted, demonstrating that robots 
                            trained in competitive environments outperform ones that are trained with SoTA algorithms in single 
                            robot environment.

                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://ieeexplore.ieee.org/abstract/document/10611581" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/KJaebye/Multiagent-Race" target="_blank">Code</a></div>
                <div class="dropdown"><span></span><a href="https://youtu.be/If7brGEzYNs" target="_blank">Video</a></div>
            </aside>
        </div>
        <br><br>

        <!-- 2023aim  -->
        <div onmouseout="aim_stop()" onmouseover="aim_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="aim_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2023aim_2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2023aim_1.png" width="100%">
                </div>
                <script type="text/javascript">
                    function aim_start() {
                    document.getElementById('aim_image').style.opacity = "1";
                    }

                    function aim_stop() {
                    document.getElementById('aim_image').style.opacity = "0";
                    }
                    aim_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> A Multi-modal Deformable Land-air Robot for Complex Environments </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=gVuaz7QAAAAJ" target="_blank">Yuanhao Huang</a>, 
                    <b>Kangyao Huang</b><ion-icon name="mail-outline"></ion-icon>, 
                    <a style="color: #999;">Xiaoyu Wang</a>, 
                    <a style="color: #999;">Dafeng Jin</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>, 
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em>IEEE/ASME International Conference on Advanced Intelligent Mechatronics (<b>AIM</b>) 2023 </em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://github.com/THU-MIR/Deformable-Aerial-Ground-Platform" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            Single locomotion robots often struggle to adapt in highly variable or uncertain environments, 
                            especially in emergencies. In this paper, a multi-modal deformable robot is introduced that can both fly and 
                            drive. Compatibility issues with multi-modal locomotive fusion for this hybrid land-air robot are solved using
                             proposed design conceptions, including power settings, energy selection, and designs of deformable structure.
                              The robot can also automatically transform between land and air modes during 3D planning and tracking. 
                              Meanwhile, we proposed a algorithms for evaluation the performance of land-air robots. A series of 
                              comparisons and experiments were conducted to demonstrate the robustness and reliability of the proposed 
                              structure in complex field environments.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://arxiv.org/pdf/2210.16875.pdf" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/THU-MIR/Deformable-Aerial-Ground-Platform" target="_blank">Code</a></div>
                <div class="dropdown"><span></span><a href="https://www.youtube.com/watch?v=kGzKuHy6CmA" target="_blank">Video</a></div>
            </aside>
        </div>
        <br>
        <br>

        <!-- 2023tmech  -->
        <div onmouseout="tmech_stop()" onmouseover="tmech_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="tmech_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2023tmech_2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2023tmech.png" width="100%" height="100%">
                </div>
                <script type="text/javascript">
                    function tmech_start() {
                    document.getElementById('tmech_image').style.opacity = "1";
                    }

                    function tmech_stop() {
                    document.getElementById('tmech_image').style.opacity = "0";
                    }
                    tmech_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Coupled Modeling and Fusion Control for a Multi-modal Deformable Land-air Robot </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=gVuaz7QAAAAJ" target="_blank">Yuanhao Huang</a>, 
                    <b>Kangyao Huang</b><ion-icon name="mail-outline"></ion-icon>, 
                    <a style="color: #999;">Ziqi Zhao</a>, 
                    <a style="color: #999;">Jingwei Li</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>, 
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> Submitted to RAS </em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://github.com/THU-MIR/Deformable-Aerial-Ground-Platform" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            This paper introduces a structure-deformable land-air robot which possesses both excellent ground driving 
                            and flying ability, with smooth switching mechanism between two modes. The elaborate coupled dynamics model 
                            of the proposed robot is established, including rotors, chassis, especially the deformable structures. 
                            Furthermore, taking fusion locomotion and complex near-ground situations into consideration, a model based 
                            controller is designed for landing and mode switching under various harsh conditions, in which we realise the 
                            cooperation between fused two motion modes. The entire system is implemented in ADAMS/Simulink simulation and 
                            in practical. We conduct experiments under various complex scenarios. The results show our robot can 
                            accomplish land-air switching swiftly and smoothly, and the designed controller can effectively improve the 
                            landing flexibility and reliability.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://arxiv.org/pdf/2211.04185.pdf" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/THU-MIR/Deformable-Aerial-Ground-Platform" target="_blank">Code</a></div>
            </aside>
        </div>
        <br>
        <br>

        <!-- 2023icuas  -->
        <div onmouseout="icuas_stop()" onmouseover="icuas_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="icuas_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2023ICUAS_1.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2023ICUAS.png" width="100%">
                </div>
                <script type="text/javascript">
                    function icuas_start() {
                    document.getElementById('icuas_image').style.opacity = "1";
                    }

                    function icuas_stop() {
                    document.getElementById('icuas_image').style.opacity = "0";
                    }
                    icuas_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Path Planning for Air-Ground Robot Considering Modal Switching Point Optimization </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a style="color: #999;">Xiaoyu Wang</a>,
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a style="color: #999;">Honglin Sun</a>, 
                    <a style="color: #999;">Wenzhuo Liu</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>, 
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> International Conference on Unmanned Aircraft Systems (<b>ICUAS</b>) 2023 </em>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://github.com/THU-MIR/ABAS_matlab" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            An innovative sort of mobility platform that can both drive and fly is the air-ground robot. 
                            The need for an agile flight cannot be satisfied by traditional path planning techniques for 
                            air-ground robots. Prior studies had mostly focused on improving the energy efficiency of paths, 
                            seldom taking the seeking speed and optimizing take-off and landing places into account. A robot for the 
                            field application environment was proposed, and a lightweight global spatial planning technique for the 
                            robot based on the graph-search algorithm taking mode switching point optimization into account, with an 
                            emphasis on energy efficiency, searching speed, and the viability of real deployment. The fundamental 
                            concept is to lower the computational burden by employing an interchangeable search approach that combines 
                            planar and spatial search. Furthermore, to safeguard the health of the power battery and the integrity of 
                            the mission execution, a trap escape approach was also provided. Simulations are run to test the 
                            effectiveness of the suggested model based on the field DEM map. The simulation results show that our 
                            technology is capable of producing finished, plausible 3D paths with a high degree of believability. 
                            Additionally, the mode-switching point optimization method efficiently identifies additional acceptable 
                            places for mode switching, and the improved paths use less time and energy.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://ieeexplore.ieee.org/abstract/document/10156162" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/THU-MIR/ABAS_matlab" target="_blank">Code</a></div>
            </aside>
        </div>
        <br><br>

        <!-- 2023中国科学  -->
        <div onmouseout="scichina_stop()" onmouseover="scichina_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="scichina_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2023scichina.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2023scichina.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function scichina_start() {
                    document.getElementById('scichina_image').style.opacity = "1";
                    }

                    function scichina_stop() {
                    document.getElementById('scichina_image').style.opacity = "0";
                    }
                    scichina_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitleSmall">1: State-of-the-art and Technical Trends of Intelligent Flying Cars</h2>
                <h3 class="sectionContentSubTitleSmall">
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a><ion-icon name="mail-outline"></ion-icon>, 
                    <a style="color: #999;">Songsong Rong</a>,
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>,
                    <a href="https://www.cae.cn/cae/html/main/colys/00679747.html" target="_blank">Deyi Li</a>,
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=gVuaz7QAAAAJ" target="_blank">Yuanhao Huang</a>, 
                    <b>Kangyao Huang</b>,
                    <a href="https://scholar.google.com.hk/citations?user=pKCG3T8AAAAJ" target="_blank">Jianxi Luo</a>,
                </h3>
                <h3 class="sectionContentSubTitleSmall">
                    <em> 中国科学（技术科学）, SCIENTIA SINICA Techinologica, 2024</em>, <a style="color: rgb(247, 121, 175);font-weight: bold;font-style: oblique;font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">TH-CPL-A</a>, <a style="color: rgb(247, 121, 175);font-weight: bold;font-style: oblique;font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">2024年4月-第54卷第4期封面文章-Cover Paper</a>
                </h3>
                <h2 class="sectionContentTitleSmall">2: Wind-Resistant Flight Control for Amphibious Flying Car</h2>
                <h3 class="sectionContentSubTitleSmall">
                    <b>Kangyao Huang</b>,
                    <a style="color: #999;">Baoshang Zhou</a>,
                    <a style="color: #999;">Songsong Rong</a>,
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a><ion-icon name="mail-outline"></ion-icon>,
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a><ion-icon name="mail-outline"></ion-icon>
                </h3>
                <h3 class="sectionContentSubTitleSmall">
                    <em> International Conference on Guidance, Navigation and Control (<b>ICGNC</b>) 2024</em>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            城市立体交通是未来智慧出行发展的热点方向, 近年来受到了广泛的关注. 作为城市立体交通的载体, 智能飞行汽车融合了飞机与汽车两种运动模态, 
                            能够灵活地在空中与地面进行切换. 本文介绍了智能飞行汽车 的背景、历史与现状、阐述了其与城市空中交通载具的区别，分析与讨论了飞行汽车的系统设计，
                            并介绍了智 能飞行汽车的关键技术创新，包括动力技术和机电总体设计、多模态切换、模块复用与飞车脑认知等。重点讨 论了飞行汽车的智能化技术，
                            包括近地感知、决策与规划、智能控制与智能通信系统的关键技术与瓶颈. 最后, 结 合现有技术, 对智能飞行汽车的技术进行了剖析, 
                            并讨论了潜在的解决方案与发展趋势.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://www.sciengine.com/SST/doi/10.1360/SST-2023-0098" target="_blank">Paper</a></div>
            </aside>
        </div>
        <br>


        <!-- 2022tiv  -->
        <div onmouseout="tiv_stop()" onmouseover="tiv_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="tiv_image">
                        <video  width="100%" muted="" autoplay="" loop="">
                            <source src="material/2022tiv_1.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2022tiv_1.png" width="100%">
                </div>
                <script type="text/javascript">
                    function tiv_start() {
                    document.getElementById('tiv_image').style.opacity = "1";
                    }

                    function tiv_stop() {
                    document.getElementById('tiv_image').style.opacity = "0";
                    }
                    tiv_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Intelligent Amphibious Ground-aerial Vehicles: State of the Art Technology for Future Transportation </h2>
                <h3 class="sectionContentSubTitle"> 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a style="color: #999;">Jiangeng Huang</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=gVuaz7QAAAAJ" target="_blank">Yuanhao Huang</a>, 
                    <b>Kangyao Huang</b><ion-icon name="mail-outline"></ion-icon>, 
                    <a href="https://scholar.google.com.hk/citations?user=EUnI2nMAAAAJ" target="_blank">Lei Yang</a>, 
                    <a style="color: #999;">Yan Han</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=kLTnwAsAAAAJ" target="_blank">Li Wang</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=HXnkIkwAAAAJ" target="_blank">Huaping Liu</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=pKCG3T8AAAAJ" target="_blank">Jianxi Luo</a>, 
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> IEEE Transactions on Intelligent Vehicles (<b>T-IV</b>) 2022</em> 
                    <em></em>
                    <a style="color: rgb(247, 121, 175);font-weight: bold;font-style: oblique;font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">IF: 14</a>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            Amphibious ground-aerial vehicles fuse flying and driving modes to enable more flexible air-land 
                            mobility and have received growing attention recently. By analyzing the existing amphibious vehicles, 
                            we highlight the autonomous fly-driving functionality for the effective uses of amphibious vehicles in 
                            complex three-dimensional urban transportation systems. We review and summarize the key enabling 
                            technologies for intelligent flying-driving in existing amphibious vehicle designs, identify major 
                            technological barriers and propose potential solutions for future research and innovation. This paper 
                            aims to serve as a guide for research and development of intelligent amphibious vehicles for urban 
                            transportation toward the future.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://ieeexplore.ieee.org/abstract/document/9839587" target="_blank">Paper</a></div>
            </aside>
        </div>
        <br>

        <!-- 2021ciac  -->
        <div onmouseout="ciac_stop()" onmouseover="ciac_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="ciac_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2021CIAC.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2021CIAC0.png" width="100%">
                </div>
                <script type="text/javascript">
                    function ciac_start() {
                    document.getElementById('ciac_image').style.opacity = "1";
                    }

                    function ciac_stop() {
                    document.getElementById('ciac_image').style.opacity = "0";
                    }
                    ciac_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Bio-inspired Multi-agent Model and Optimization Strategy for Collaborative Aerial Transport </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=j63_EA0AAAAJ" target="_blank">Jingyu Chen</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=W7ePGWYAAAAJ" target="_blank">John Oyekan</a><ion-icon name="mail-outline"></ion-icon>, 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a> 
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em> Chinese Intelligent Automation Conference (<b>CIAC</b>) 2021 </em>
                    <a style="color: rgb(247, 121, 175);font-weight: bold;font-style: oblique;font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">Best Student Paper</a>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            Collaboration between robots provides solutions for transporting more complex and heavier loads. 
                            In this work, inspired by the ant colony foraging and transport, we put forward two collaborative models, 
                            Coupled-Carriers and Navigator-Carrier, for aerial cooperative transport. To achieve this, a linear quadratic 
                            regulator (LQR) is applied to optimize the performance. The results show the task of dual-drone transport 
                            of a bar load is successfully accomplished.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="https://eprints.whiterose.ac.uk/176758/1/Bio-inspired%20Multi-agent%20Model%20and%20Optimization%20Strategy%20for%20Collaborative%20Aerial%20Transport.pdf" target="_blank">Paper</a></div>
            </aside>
        </div>
        <br>

        <!-- 2023swevo  -->
        <div onmouseout="swevo_stop()" onmouseover="swevo_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="swevo_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2021SWEVO.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2021SWEVO.png" width="100%">
                </div>
                <script type="text/javascript">
                    function swevo_start() {
                    document.getElementById('swevo_image').style.opacity = "1";
                    }

                    function swevo_stop() {
                    document.getElementById('swevo_image').style.opacity = "0";
                    }
                    swevo_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Decentralised Aerial Swarm for Adaptive and Energy Efficient Transport of Unknown Loads </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Kangyao Huang</b>, 
                    <a href="https://scholar.google.com.hk/citations?user=j63_EA0AAAAJ" target="_blank">Jingyu Chen</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=W7ePGWYAAAAJ" target="_blank">John Oyekan</a><ion-icon name="mail-outline"></ion-icon> 
                </h3>
                <h3 class="sectionContentSubTitle">
                    <em>Swarm and Evolutionary Computation (<b>SWEVO</b>) 2021 </em>
                    <a style="color: rgb(247, 121, 175);font-weight: bold;font-style: oblique;font-family: 'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">IF: 8.2</a>
                </h3>
            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://github.com/KJaebye/Drone-Swarm-Cooperative-Transport" target="_blank">Project Page</a>
                </div>
                <div class="dropdown"> <span>Abstract</span>
                    <div class="dropdown-content">
                        <p style="text-align:left;font-size: 10px">
                            Cooperative transport by a swarm of Quadcopters offers more flexibility and performance when carrying loads 
                            that are complex in structural profile and mass. Ensuring that team members of the swarm are optimally placed 
                            on these loads as well as able to resist disturbances from the environment during transport are current 
                            research challenges. In this paper, we present a decentralized behaviour based subsumption architecture for 
                            enabling a swarm of Quadcopters to explore an unfamiliar area, find a load and transport it to a target 
                            location cooperatively. In the architecture, three behaviours were used: an obstacle avoidance behaviour to 
                            avoid collisions with objects in the environment, a flocking behaviour to ensure swarm structure and a 
                            bacterium behaviour for exploration of the environment and to adapt to the mass profile of various detected 
                            loads.<br><br>

                            By adapting to the mass profile of a detected load, we show that our architecture ensures even energy 
                            distribution among Quadcopters while achieving robustness to disturbances from the environment. Our results 
                            show that a mass adapting swarm is able to conserve energy during payload transportation when compared to a 
                            swarm that does not adapt to a load's profile. Furthermore, we do not use explicit communication between team 
                            members but instead rely on data from visual sensors attached to the Quadcopters. We experiment with 
                            simulations in a physics informed robot simulator called CoppeliaSim and demonstrate the effectiveness of our 
                            architecture when utilized for cooperative transport of irregular loads.
                        </p>
                    </div>
                </div>
                <div class="dropdown"><span></span><a href="publications/2021_SWEVO_Decentralised aerial swarm for adaptive and energy efficient transport of unknown loads.pdf" target="_blank">Paper</a></div>
                <div class="dropdown"><span></span><a href="https://github.com/KJaebye/Drone-Swarm-Cooperative-Transport" target="_blank">Code</a></div>
            </aside>
        </div>

        <br><br>
	</section>

    <!-- Projects -->
    <section class="section2">
        <h2 class="sectionTitle">Projects</h2>
        <!-- <hr class="sectionTitleRule"> -->
        <hr class="sectionTitleRule2">

        <!-- emNavi  -->
        <div onmouseout="emNavi_stop()" onmouseover="emNavi_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="emNavi_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/X152b-ego_1.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/X152b-ego.png" width="100%">
                </div>
                <script type="text/javascript">
                    function emNavi_start() {
                    document.getElementById('emNavi_image').style.opacity = "1";
                    }

                    function emNavi_stop() {
                    document.getElementById('emNavi_image').style.opacity = "0";
                    }
                    emNavi_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"><img src="material/logo1.png" alt="emNavi" style="height: 30px; vertical-align: middle;"></h2>
                    <p style="font-size: 10px;"><b>emNavi</b> derives from "Embodied Navigation". 
                        The vision of emNavi is to make navigation more intelligent. Besides, emNavi is an open-sourced project that re-construct and optimize the navigation-related SoTA (state of the art) 
                        algorithms and apply them on robots, especially aerial robots, to promote the implementation of Embodied AI 
                        on mobile robots. </p>
                </h2>

            </section>
            <aside class="externalResourcesNav" style="margin-top:0%"> 
                <div class="dropdown">
                    <span></span><a href="https://emnavi.tech/" target="_blank">emNavi</a>
                </div>
                <div class="dropdown">
                    <span></span><a href="https://emnavi.tech/droneKit/" target="_blank">X152b</a>
                </div>
                <div class="dropdown">
                    <span></span><a href="https://emnavi.tech/AirGym/" target="_blank">Sim2Real</a>
                </div>
            </aside>
        </div>
        <br>

        <!-- vps  -->
        <div onmouseout="vps_stop()" onmouseover="vps_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="vps_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/vps_2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/vps.png" width="100%">
                </div>
                <script type="text/javascript">
                    function vps_start() {
                    document.getElementById('vps_image').style.opacity = "1";
                    }

                    function vps_stop() {
                    document.getElementById('vps_image').style.opacity = "0";
                    }
                    vps_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> GhostLoc: Geospatial High-precise Optical System for Tactical Localization</h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Work with</b> 
                    <a style="color: #999;"> teammates </a><a style="font-style: italic;">@emNavi</a>: Kai Tang (CV), Hao Wang (System), Wantong Qin (Design), Tao Peng (Hardware)
                </h3>
                <p style="font-size: 10px;"><b>Brief:</b> GhostLoc is a compact, high-altitude visual positioning system that achieves GPS-level precision in denied environments by fusing Visual-Inertial Odometry (VIO) with a Visual Positioning System (VPS). Requiring only a single camera, IMU, and barometer, its lightweight, palm-sized design provides smooth, 6-DoF pose data at over 15 Hz with meter-level accuracy, enabling robust navigation for various aerial platforms without relying on GNSS signals. We integrated XFeat, LightGlue, and VINS-fusion in one rubust framework which is running on onboard computer with RK3588s. We tested the system on DJI Matric 350 platform for a long duration flight over 5km and 300~800m height. Kai Tang and Hao Wang are main contributors for this work.</p>
            </section>
        </div>
        <br>

        <!-- flyingcar  -->
        <div onmouseout="flyingcar_stop()" onmouseover="flyingcar_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="flyingcar_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/flyingcar_2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                        <aside class="externalResourcesNav" style="margin-top:0%">
                            <div class="dropdown">
                                <span></span><a href="https://mp.weixin.qq.com/s/u-WIZV_5p_Ua6ohFrNEB9Q" target="_blank">News</a>
                            </div>
                            <div class="dropdown"><span></span><a href="https://www.bilibili.com/video/BV1gN4y1a72Z/" target="_blank">Video</a></div>
                        </aside>
                    </div>
                    <img src="material/flyingcar.png" width="100%">
                </div>
                <script type="text/javascript">
                    function flyingcar_start() {
                    document.getElementById('flyingcar_image').style.opacity = "1";
                    }

                    function flyingcar_stop() {
                    document.getElementById('flyingcar_image').style.opacity = "0";
                    }
                    flyingcar_stop()
                </script>
                
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> the Implementation of Flying Car for Ground-aerial Transportation</h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Partners:</b>
                    <a style="font-style: italic;font-size: 10px;" href="http://www.svm.tsinghua.edu.cn/">@School of Vehicle and Mobility, THU</a>
                    <a style="font-style: italic;font-size: 10px;" href="https://www.cs.tsinghua.edu.cn/">@Department of Computer Science and Technology, THU</a>
                    <a style="font-style: italic;font-size: 10px;" href="https://www.tsari.tsinghua.edu.cn/">@Suzhou Automobile Research Institute-CN</a>
                    <a style="font-style: italic;font-size: 10px;" href="https://www.sutd.edu.sg/">@Singapore University of Technology and Design</a>
                    <a style="font-style: italic;font-size: 10px;" href="https://www.81uav.cn/com/bingouav/">@Bingo Intelligence Co., Ltd.</a>
                    <a style="font-style: italic;font-size: 10px;" href="http://www.fullymax.com/">@Fullymax Co., Ltd.</a>
                    <a style="font-style: italic;font-size: 10px;" href="http://www.xy-uav.com/">@XY-UAV Co., Ltd.</a>
                    <a style="font-style: italic;font-size: 10px;" href="https://www.robosense.cn/index">@RoboSense Co., Ltd.</a>
                </h3>
                <h3 class="sectionContentSubTitle"> 
                    Project Principal:
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    Project Technical Leader:
                    <b>Kangyao Huang</b>,
                    Director:
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>                    
                </h3>
                <h3 class="sectionContentSubTitle">
                    <a style="font-size: 12px;">Other participants: </a>
                    <a style="font-size:9px; line-height: 3px;">Qihao Zhu, Qingjing Meng, Bo Cui, Songsong Rong, Haowen Shen, Guole Li, Huaping Liu, Jianxi Luo, Dafeng Jin, 
                        Jun Yang, Shuzhi Ge, Weiguo Yang, Yu Wan, Zhiqiang Yang, Zhenlong Ding, Xiaofeng Xu, Jiang Qian, Chaoyang Ha, Yuanhao Huang, Qiujiang Wu, Xingang Wu, Qifan Tan, Mo Zhou, Yang Shen, Li Wang, Yan Han, Zhaosheng Huang, Zhiwei Li, Lei Yang, Linxun Shi, Dazhong Xu, Kai Tang, et cetera.</a>
                </h3>
                <p style="font-size: 10px;color: rgb(135, 4, 187);">In 2021, we successfully developed the first generation of Tsinghua Mengshi intelligent flying car. This vehicle is the world first electric manned rotorcraft amphibious ground-aerial vehicle with integrated intelligent driving function.
                </p>
            </section>
        </div>
        <br>

        <!-- 2021ad  -->
        <div onmouseout="ad_stop()" onmouseover="ad_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="ad_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/2021ad.png" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/2021ad.png" width="100%">
                </div>
                <script type="text/javascript">
                    function ad_start() {
                    document.getElementById('ad_image').style.opacity = "1";
                    }

                    function ad_stop() {
                    document.getElementById('ad_image').style.opacity = "0";
                    }
                    ad_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Roadside Autonomous Driving Architecture towards SCSTSV </h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Director:</b>
                    <a style="color: #999;">Qifan Tan</a>, 
                    <a href="https://scholar.google.com.hk/citations?user=0Q7pN4cAAAAJ" target="_blank">Xinyu Zhang</a>, 
                    <a href="https://www.tsinghua.edu.cn/info/1166/93890.htm" target="_blank">Jun Li</a>
                    <a style="font-style: italic;">@New Technology Concept Vehicles, THU</a>
                </h3>
                <p style="font-size: 10px;"><b>Brief:</b> Towards the Smart City-Smart Transportation-Smart Vehicles(SCSTSV), we focus on the key areas of autonomous 
                    driving technology, particularly in the design and optimization of architectures for perception, decision-making, 
                    and control. I propose a comprehensive architecture that integrates perception, decision-making, and control into a unified framework, further enhancing 
                    system performance through the integration of road testing equipment.</p>
            </section>
        </div>
        <br>

        <!-- solar-uav  -->
        <div onmouseout="solar_stop()" onmouseover="solar_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="solar_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/solar-uav_2.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/solar-uav-pic.png" width="100%">
                </div>
                <script type="text/javascript">
                    function solar_start() {
                    document.getElementById('solar_image').style.opacity = "1";
                    }

                    function solar_stop() {
                    document.getElementById('solar_image').style.opacity = "0";
                    }
                    solar_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Solar-powered UAV for Long Duration Cruising</h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Work with</b>
                    <a style="color: #999;">Colleagues </a><a style="font-style: italic;">@Bingo Intelligence Co., Ltd.</a>
                </h3>
                <p style="font-size: 10px;"><b>Brief:</b> In 2017, we built a solar-powered unmanned aerial vehicles and focused on enhancing the endurance. Additionally, our team developed a dynamic power system with low vortex drag variable-pitch propellers to adapt to varying wind speeds during flight, enabling them to operate efficiently across diverse conditions. This research contributes to the advancement of renewable energy-powered UAV technology.</p>
                <p style="font-size: 10px;color: rgba(1, 145, 193, 0.579);">
                We honor the memory of Zhaoxi Wang, one of co-founders of the team, whose dedication and vision continue to inspire us as we move forward, and his spirit will forever remain an integral part of our journey,just like his aircraft did.
                </p>
            </section>
        </div>
        <br>

        <!-- evtol tracking  -->
        <div onmouseout="evtol_stop()" onmouseover="evtol_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="evtol_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/evtol_tracking.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/evtol_tracking.png" width="100%">
                </div>
                <script type="text/javascript">
                    function evtol_start() {
                    document.getElementById('evtol_image').style.opacity = "1";
                    }

                    function evtol_stop() {
                    document.getElementById('evtol_image').style.opacity = "0";
                    }
                    evtol_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Auto-Patrolling eVTOL UAV and Tracking System</h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Work with</b> 
                    <a style="color: #999;">Colleagues </a><a style="font-style: italic;">@Bingo Intelligence Co., Ltd.</a>
                </h3>
                <p style="font-size: 10px;"><b>Brief:</b> This project developed an Auto-Patrolling eVTOL UAV and Tracking System, integrating the vertical takeoff and landing capability of an electric Vertical Take-Off and Landing (eVTOL) aircraft with advanced computer vision for autonomous detection and real-time tracking of targets, enabling automated surveillance and monitoring missions in dynamic environments such as security, traffic, and infrastructure inspection. For this purpose, we <b>designed and developed this UAV entirely from scratch</b>, encompassing its aerodynamic profile, airframe structure and composite materials, flight control systems, and cv detection capabilities based on third party optical device.</p>
            </section>
        </div>
        <br>

        <!-- auto-patrolling  -->
        <!-- <div onmouseout="patrolling_stop()" onmouseover="patrolling_start()">	  
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="patrolling_image">
                        <video  width="100%" height="100%" muted="" autoplay="" loop="">
                            <source src="material/auto-patrolling.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/auto-patrolling.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function patrolling_start() {
                    document.getElementById('patrolling_image').style.opacity = "1";
                    }

                    function patrolling_stop() {
                    document.getElementById('patrolling_image').style.opacity = "0";
                    }
                    patrolling_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Auto-Patralling UAV Platform</h2>
                <h3 class="sectionContentSubTitle"> 
                    <b>Work with</b> 
                    <a style="color: #999;">Colleagues </a><a style="font-style: italic;">@Bingo Intelligence Co., Ltd.</a>
                </h3>
                <p style="font-size: 10px;"><b>Brief:</b> This project focused on the development of an autonomous inspection drone 
                    system for airports. This project encompassed the overall design of the airport system and the design and production of electromechanical controls. We prioritized the autonomous inspection functionality of the drones. Through a comprehensive approach balancing airport safety and efficiency, we devised a complete system including structural design of the drones, development of electromechanical control systems, and optimization of inspection algorithms. This system not only enables comprehensive inspection of airport facilities but also autonomously responds to and alerts to anomalies.</p>
            </section>
        </div>
        <br> -->
        
        <!-- oil-drone  -->
        <div onmouseout="oil_stop()" onmouseover="oil_start()">
            <div class="sectionContent" style="padding:0px;vertical-align:middle">
                <div class="one">
                    <div class="two" id="oil_image">
                        <video  width="100%" muted="" autoplay="" loop="">
                            <source src="material/oil-drone.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                        </video>
                    </div>
                    <img src="material/oil-drone.jpg" width="100%">
                </div>
                <script type="text/javascript">
                    function oil_start() {
                    document.getElementById('oil_image').style.opacity = "1";
                    }

                    function oil_stop() {
                    document.getElementById('oil_image').style.opacity = "0";
                    }
                    oil_stop()
                </script>
            </div>
            <section class="section2Content">
                <h2 class="sectionContentTitle"> Oil-powered Variable-pitch Quadrotor</h2>
                <p style="font-size: 10px;"><b>My dissertation for BEng degree.</b> Notably, this is the <b>first successful flight</b> of oil-powered rotary-wing UAV utilizing variable-pitch control in China. We finished it at the end of 2015. Work with teammates Fanjie Kong, Jingdong Ma.</p>
                <p style="font-size: 10px;"><b>Brief:</b> In 2015, I participated a groundbreaking project focused on the development of an oil-powered variable-pitch multirotor unmanned aerial vehicle (UAV). This project involved the comprehensive 
                design and prototyping testing of the UAV. Our efforts encompassed the integration of advanced variable-pitch 
                technology with traditional oil-powered UAV systems, leading to a novel and efficient aerial platform. We use 
                gears and belts as the power transmission method, where belts can effectively reduce the vibrations generated 
                by the engine. The successful flight testing signifies a significant milestone in the domestic UAV industry, showcasing the feasibility and potential of variable-pitch control in enhancing the performance and 
                versatility of oil-powered UAVs. </p>
            </section>
        </div>

    </section>
    <br>

    <!-- Education -->
    <section class="section2">
        <h2 class="sectionTitle">Education</h2>
        <hr class="section2">

        <div class="section2" style="padding:0px;vertical-align:middle;line-height: 10px;">
            <group>
                <img src="profile/清华logo.png" width="3%" height="3%">
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;2022~now,&emsp;</p>
                <p>
                    <a style="font-weight: bold; font-size: 11px;">PhD</a> candidate in Computer Science and Technology, <a style="font-weight: bold; font-size: 11px;">Tsinghua University</a>, China
                </p>
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;Dissertation:&emsp;</p><p style="font-style: italic; font-size: 11px;"> Robot Interactive Learning</p>
            </group>
            <group>
                <img src="profile/UoS.jpg" width="3%" height="3%">
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;2019~2020,&emsp;</p>
                <p>
                    <a style="font-weight: bold; font-size: 11px;">MRes</a> in Control & Systems Engneering, <a style="font-weight: bold;color: rgb(4, 113, 222); font-size: 11px;" href="https://www.sheffield.ac.uk/acse">ACSE</a>, <a style="font-weight: bold; font-size: 11px;">the University of Sheffied</a>, UK
                </p>
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;Dissertation:&emsp;</p><p style="font-style: italic; font-size: 11px;">Cooperative Transport by Swarm Robots</p>
            </group>
            <group>
                <img src="profile/西工大校标大图 蓝白版.jpg" width="3%" height="3%">
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;2012~2016,&emsp;</p>
                <p>
                    <a style="font-weight: bold; font-size: 11px;">BEng</a> in Aircraft Design and Engineering, <a style="font-weight: bold;color: rgb(1, 98, 195); font-size: 11px;" href="https://hangtian.nwpu.edu.cn/">School of Astronautics</a>, <a style="font-weight: bold; font-size: 11px;">Northwestern Polytechnical University</a>, China
                </p>
                <p style="font-weight: bold;font-style: italic; font-size: 11px;">&emsp;Dissertation:&emsp;</p><p style="font-style: italic; font-size: 11px;">Oil-powered Quadrotor</p>
            </group>
        </div>

    </section>

    <br>
    <!-- Award -->
    <section class="section2">
        <h2 class="sectionTitle">Awards</h2>
        <hr class="section2">

        <div class="section2" style="padding:0px;vertical-align:middle;line-height: 5px;">
            <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2021,&ensp;</h3>
                <h3 class="sectionContentSubTitle">
                    Bronze Medal at the International Exhibition of Inventions of Geneva
                </h3>
            </group>
            <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2021,&ensp;</h3>
                <h3 class="sectionContentSubTitle">
                    Best Student Paper Award at Chinese Intelligent Automation Conference (CIAC)
                </h3>
            </group>
            <!-- <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2024,&ensp;</h3>
                <h3 class="sectionContentSubTitle">
                    Yang Huiyan Scholarship at Tsinghua University（惠妍英才奖学金-清华大学）
                </h3>
            </group>
            <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2025,&ensp;</h3>
                <h3 class="sectionContentSubTitle">
                    HuangPu Scholarship at Tsinghua University（黄埔英才奖学金-清华大学）
                </h3>
            </group> -->
            <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2025,&ensp;</h3>
                <h3 class="sectionContentSubTitle">
                    <a style="font-weight: bold;">First Prize</a> at CICC Science and Technology Progress Award-Technology Invention（中国指控学会科技进步奖技术发明类一等奖）无人系统具身交互感知关键技术及应用
                </h3>
            </group>
        </div>
    </section>

    <br>
    <!-- Experiences -->
    <section class="section2">
        <h2 class="sectionTitle">Experiences</h2>
        <hr class="section2">

        <div class="section2" style="padding:0px;vertical-align:middle;line-height: 5px;">
            <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2015~2019,&emsp;</h3>
                <h3 class="sectionContentSubTitle">
                    <a style="font-weight: bold;">Co-Founder</a> @<a style="font-weight: bold;color: rgb(112, 112, 112);">Bingo Intelligence Co. Ltd.</a>, Xi'an, ShaanXi, China.
                </h3>
            </group>
            <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2020~2022,&emsp;</h3>
                <h3 class="sectionContentSubTitle">
                    <a style="font-weight: bold;">Research assistant</a> @Institute for New Technology Concept Vehicles,<a style="font-weight: bold;color: rgb(113, 112, 114);"> THU</a>, Beijing, China
                </h3>
            </group>
            <group>
                <h3 class="sectionContentSubTitle" style="font-weight: bold;font-style: italic;">2023~now,&emsp;</h3>
                <h3 class="sectionContentSubTitle">
                    <a style="font-weight: bold;">Founder</a> & Aerospace Engineer <a>@超微智导技术</a></a>, China
                </h3>
            </group>
        </div>

    </section>
    <br><br>

	  
  <hr>
  
</section>

<footer>
  <p class="footerDisclaimer">Updated by KJaebye<span></span></p>
  <p class="footerNote"></p>
</footer>

<script type="module" src="https://unpkg.com/ionicons@7.1.0/dist/ionicons/ionicons.esm.js"></script>
<script nomodule src="https://unpkg.com/ionicons@7.1.0/dist/ionicons/ionicons.js"></script>

</body>
</html>
